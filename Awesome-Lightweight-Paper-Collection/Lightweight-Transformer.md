# Awesome Lightweight Transformer Paper Collection


- [2024](#2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICCV](#iccv-2023)
  - [ICML](#icml-2023)
  - [IJCAI](#ijcai-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [IJCAI](#ijcai-2022)

- [2021](#2021)
  - [CVPR](#cvpr-2021)
  - [ICCV](#iccv-2021)

- [2019](#2019)
  - [AAAI](#aaai-2019)



# 2024


## ICLR-2024


- Boosting Vanilla Lightweight Vision Transformers via Re-parameterization [[paper](https://iclr.cc/virtual/2024/poster/19492)]


## AAAI-2024


- Efficient Lightweight Image Denoising with Triple Attention Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28604)]



# 2023


## NeurIPS-2023


- Lightweight Vision Transformer with Bidirectional Interaction [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/3170de57bc1899315b97712043d8bb22-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.00396)] [[paper with code](https://paperswithcode.com/paper/lightweight-vision-transformer-with-1)] [[code](https://github.com/qhfan/fat)] [[openview](https://openreview.net/forum?id=492Hfmgejy)]


## CVPR-2023


- Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Lite-Mono_A_Lightweight_CNN_and_Transformer_Architecture_for_Self-Supervised_Monocular_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.13202)] [[paper with code](https://paperswithcode.com/paper/lite-mono-a-lightweight-cnn-and-transformer)] [[code](https://github.com/noahzn/lite-mono)]

- N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.11436)] [[paper with code](https://paperswithcode.com/paper/n-gram-in-swin-transformers-for-efficient)] [[code](https://github.com/rami0205/ngramswin)]


## ICCV-2023


- Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.06904)] [[paper with code](https://paperswithcode.com/paper/exploring-lightweight-hierarchical-vision)]


## ICML-2023


- A Closer Look at Self-Supervised Lightweight Vision Transformers [[paper](https://proceedings.mlr.press/v202/wang23e.html)] [[arxiv](https://arxiv.org/abs/2205.14443)] [[paper with code](https://paperswithcode.com/paper/a-closer-look-at-self-supervised-lightweight)] [[code](https://github.com/wangsr126/mae-lite)]


## IJCAI-2023


- Sign Language-to-Text Dictionary with Lightweight Transformer Models [[paper](https://www.ijcai.org/proceedings/2023/662)]


## AAAI-2023


- Head-Free Lightweight Semantic Segmentation with Linear Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25126)] [[arxiv](https://arxiv.org/abs/2301.04648)] [[paper with code](https://paperswithcode.com/paper/head-free-lightweight-semantic-segmentation)] [[code](https://github.com/dongbo811/afformer)]

- FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25187)] [[arxiv](https://arxiv.org/abs/2212.03145)] [[paper with code](https://paperswithcode.com/paper/fact-factor-tuning-for-lightweight-adaptation)] [[code](https://github.com/jieshibo/petl-vit)]



# 2022


## IJCAI-2022


- Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer [[paper](https://www.ijcai.org/proceedings/2022/128)] [[arxiv](https://arxiv.org/abs/2204.13286)] [[paper with code](https://paperswithcode.com/paper/lightweight-bimodal-network-for-single-image)] [[code](https://github.com/iviplab/lbnet)]


# 2021


## CVPR-2021


- HR-NAS: Searching Efficient High-Resolution Neural Architectures With Lightweight Transformers [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Ding_HR-NAS_Searching_Efficient_High-Resolution_Neural_Architectures_With_Lightweight_Transformers_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2106.06560)] [[paper with code](https://paperswithcode.com/paper/hr-nas-searching-efficient-high-resolution)] [[code](https://github.com/dingmyu/HR-NAS)]


## ICCV-2021


- STAR: A Structure-Aware Lightweight Transformer for Real-Time Image Enhancement [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_STAR_A_Structure-Aware_Lightweight_Transformer_for_Real-Time_Image_Enhancement_ICCV_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/star-a-structure-aware-lightweight)] [[code](https://github.com/zzyfd/STAR-pytorch)]


# 2019


## AAAI-2019


- Gaussian Transformer: A Lightweight Approach for Natural Language Inference [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4614)]