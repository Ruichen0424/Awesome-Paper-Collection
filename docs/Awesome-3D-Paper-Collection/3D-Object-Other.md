# Awesome 3D Object Other Paper Collection

- [2024](#2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICLR](#iclr-2023)
  - [ICCV](#iccv-2023)
  - [IJCAI](#ijcai-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [CVPR](#cvpr-2022)
  - [ICLR](#iclr-2022)
  - [ECCV](#eccv-2022)

- [2021](#2021)
  - [NeurIPS](#neurips-2021)
  - [CVPR](#cvpr-2021)
  - [ICLR](#iclr-2021)
  - [ICCV](#iccv-2021)
  - [IJCAI](#ijcai-2021)
  - [AAAI](#aaai-2021)

- [2020](#2020)
  - [NeurIPS](#neurips-2020)
  - [CVPR](#cvpr-2020)
  - [ICLR](#iclr-2020)
  - [ECCV](#eccv-2020)
  - [ICML](#icml-2020)
  - [IJCAI](#ijcai-2020)
  - [AAAI](#aaai-2020)

- [2019](#2019)
  - [NeurIPS](#neurips-2019)
  - [CVPR](#cvpr-2019)
  - [ICCV](#iccv-2019)
  - [IJCAI](#ijcai-2019)
  - [AAAI](#aaai-2019)

- [2018](#2018)
  - [NeurIPS](#neurips-2018)
  - [CVPR](#cvpr-2018)
  - [ECCV](#eccv-2018)
  - [IJCAI](#ijcai-2018)
  - [AAAI](#aaai-2018)



# 2024


## ICLR-2024


- 3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation [[paper](https://iclr.cc/virtual/2024/poster/18534)] [[arxiv](https://arxiv.org/abs/2310.03534)] [[paper with code](https://paperswithcode.com/paper/3d-aware-hypothesis-verification-for)] [[openreview](https://openreview.net/forum?id=U6hEOZlDf5)]

- Training-free Multi-objective Diffusion Model for 3D Molecule Generation [[paper](https://iclr.cc/virtual/2024/poster/18459)] [[openreview](https://openreview.net/forum?id=X41c4uB4k0)]

- Pre-training LiDAR-based 3D Object Detectors through Colorization [[paper](https://iclr.cc/virtual/2024/poster/18195)] [[arxiv](https://arxiv.org/abs/2310.14592)] [[paper with code](https://paperswithcode.com/paper/pre-training-lidar-based-3d-object-detectors)] [[code](https://github.com/tydpan/gpc)] [[openreview](https://openreview.net/forum?id=fB1iiH9xo7)]

- Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors [[paper](https://iclr.cc/virtual/2024/poster/19607)] [[arxiv](https://arxiv.org/abs/2306.17843)] [[paper with code](https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object)] [[code](https://github.com/guochengqian/magic123)] [[openreview](https://openreview.net/forum?id=0jHkUDyEO9)]

- AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation [[paper](https://iclr.cc/virtual/2024/poster/19289)] [[arxiv](https://arxiv.org/abs/2306.00977)] [[paper with code](https://paperswithcode.com/paper/agile3d-attention-guided-interactive-multi)] [[openreview](https://openreview.net/forum?id=9cQtXpRshE)]

- H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields [[paper](https://iclr.cc/virtual/2024/poster/18720)] [[arxiv](https://arxiv.org/abs/2402.08138)] [[paper with code](https://paperswithcode.com/paper/h2o-sdf-two-phase-learning-for-3d-indoor)] [[code](https://github.com/Domirae/H2O-SDF)] [[openreview](https://openreview.net/forum?id=P1ANzoGg3W)]


## AAAI-2024


- Hand-Centric Motion Refinement for 3D Hand-Object Interaction via Hierarchical Spatial-Temporal Modeling [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27979)] [[arxiv](https://arxiv.org/abs/2401.15987)] [[paper with code](https://paperswithcode.com/paper/hand-centric-motion-refinement-for-3d-hand)] [[code](https://github.com/holiday888/hst-net)]

- O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28002)] [[arxiv](https://arxiv.org/abs/2308.09591)]

- In-Hand 3D Object Reconstruction from a Monocular RGB Video [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28029)] [[arxiv](https://arxiv.org/abs/2312.16425)] [[paper with code](https://paperswithcode.com/paper/in-hand-3d-object-reconstruction-from-a)]

- Primitive-Based 3D Human-Object Interaction Modelling and Programming [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28161)] [[arxiv](https://arxiv.org/abs/2312.10714)] [[paper with code](https://paperswithcode.com/paper/primitive-based-3d-human-object-interaction)]

- Vision-Language Pre-training with Object Contrastive Learning for 3D Scene Understanding [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28559)] [[arxiv](https://arxiv.org/abs/2305.10714)] [[paper with code](https://paperswithcode.com/paper/vision-language-pre-training-with-object)]

- Cross-Modal Match for Language Conditioned 3D Object Grounding [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28566)]

- Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28626)] [[arxiv](https://arxiv.org/abs/2308.14078)] [[paper with code](https://paperswithcode.com/paper/sparse3d-distilling-multiview-consistent)]



# 2023


## NeurIPS-2023


- OBJECT 3DIT: Language-guided 3D-aware Image Editing [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/0b0153a91f827b14e8bfea4e211362f3-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2307.11073)] [[paper with code](https://paperswithcode.com/paper/object-3dit-language-guided-3d-aware-image)] [[openreview](https://openreview.net/forum?id=yjWVd8Fhqt)]

- Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1cb5b3d64bdf3c6642c8d9a8fbecd019-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.04633)] [[paper with code](https://paperswithcode.com/paper/contrastive-lift-3d-object-instance)] [[code](https://github.com/yashbhalgat/contrastive-lift)] [[openreview](https://openreview.net/forum?id=bbbbbov4Xu)]

- NAP: Neural 3D Articulated Object Prior [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/655846cc914cb7ff977a1ada40866441-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=TTkklyFv7e)]

- Exploiting Contextual Objects and Relations for 3D Visual Grounding [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9b91ee0da3bcd61905fcd89e770168fc-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=GlWzQhf2lV)]

- Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/bf78fc727cf882df66e6dbc826161e86-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2309.07510)] [[paper with code](https://paperswithcode.com/paper/learning-environment-aware-affordance-for-3d)] [[openreview](https://openreview.net/forum?id=Re2NHYoZ5l)]

- Objaverse-XL: A Universe of 10M+ 3D Objects [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/70364304877b5e767de4e9a2a511be0c-Abstract-Datasets_and_Benchmarks.html)] [[arxiv](https://arxiv.org/abs/2307.05663)] [[paper with code](https://paperswithcode.com/paper/objaverse-xl-a-universe-of-10m-3d-objects)] [[code](https://github.com/allenai/objaverse-xl)] [[openreview](https://openreview.net/forum?id=Sq3CLKJeiz)]

- Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/92a821f6c25b29241df6985ceb673a85-Abstract-Datasets_and_Benchmarks.html)] [[arxiv](https://arxiv.org/abs/2310.16044)] [[paper with code](https://paperswithcode.com/paper/stanford-orb-a-real-world-3d-object-inverse)] [[code](https://github.com/StanfordORB/Stanford-ORB)] [[openreview](https://openreview.net/forum?id=zRYSJbcRcV)]


## CVPR-2023


- 3D-Aware Object Goal Navigation via Simultaneous Exploration and Identification [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_3D-Aware_Object_Goal_Navigation_via_Simultaneous_Exploration_and_Identification_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.00338)] [[paper with code](https://paperswithcode.com/paper/3d-aware-object-goal-navigation-via)]

- Object Pop-Up: Can We Infer 3D Objects and Their Poses From Human Interactions Alone? [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Petrov_Object_Pop-Up_Can_We_Infer_3D_Objects_and_Their_Poses_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/object-pop-up-can-we-infer-3d-objects-and-1)] [[code](https://github.com/ptrvilya/object-popup)]

- NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hsu_NS3D_Neuro-Symbolic_Grounding_of_3D_Objects_and_Relations_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13483)] [[paper with code](https://paperswithcode.com/paper/ns3d-neuro-symbolic-grounding-of-3d-objects)]

- PVT-SSD: Single-Stage 3D Object Detector With Point-Voxel Transformer [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_PVT-SSD_Single-Stage_3D_Object_Detector_With_Point-Voxel_Transformer_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.06621)] [[paper with code](https://paperswithcode.com/paper/pvt-ssd-single-stage-3d-object-detector-with)] [[code](https://github.com/nightmare-n/pvt-ssd)]

- EFEM: Equivariant Neural Field Expectation Maximization for 3D Object Segmentation Without Scene Supervision [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Lei_EFEM_Equivariant_Neural_Field_Expectation_Maximization_for_3D_Object_Segmentation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.15440)] [[paper with code](https://paperswithcode.com/paper/efem-equivariant-neural-field-expectation)]

- Objaverse: A Universe of Annotated 3D Objects [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Deitke_Objaverse_A_Universe_of_Annotated_3D_Objects_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.08051)] [[paper with code](https://paperswithcode.com/paper/objaverse-a-universe-of-annotated-3d-objects)]

- Omnimatte3D: Associating Objects and Their Effects in Unconstrained Monocular Video [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Suhail_Omnimatte3D_Associating_Objects_and_Their_Effects_in_Unconstrained_Monocular_Video_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/omnimatte3d-associating-objects-and-their)]

- OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_OmniObject3D_Large-Vocabulary_3D_Object_Dataset_for_Realistic_Perception_Reconstruction_and_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2301.07525)] [[paper with code](https://paperswithcode.com/paper/omniobject3d-large-vocabulary-3d-object)] [[code](https://github.com/omniobject3d/omniobject3d)]

- LP-DIF: Learning Local Pattern-Specific Deep Implicit Function for 3D Objects and Scenes [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_LP-DIF_Learning_Local_Pattern-Specific_Deep_Implicit_Function_for_3D_Objects_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/lp-dif-learning-local-pattern-specific-deep)]

- Building Rearticulable Models for Arbitrary 3D Objects From 4D Point Clouds [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Building_Rearticulable_Models_for_Arbitrary_3D_Objects_From_4D_Point_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2306.00979)] [[paper with code](https://paperswithcode.com/paper/building-rearticulable-models-for-arbitrary-1)]

- NeurOCS: Neural NOCS Supervision for Monocular 3D Object Localization [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Min_NeurOCS_Neural_NOCS_Supervision_for_Monocular_3D_Object_Localization_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.17763)] [[paper with code](https://paperswithcode.com/paper/neurocs-neural-nocs-supervision-for-monocular-1)]

- Seeing Through the Glass: Neural 3D Reconstruction of Object Inside a Transparent Container [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Tong_Seeing_Through_the_Glass_Neural_3D_Reconstruction_of_Object_Inside_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13805)] [[paper with code](https://paperswithcode.com/paper/seeing-through-the-glass-neural-3d)] [[code](https://github.com/hirotong/reneus)]

- In-Hand 3D Object Scanning From an RGB Sequence [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hampali_In-Hand_3D_Object_Scanning_From_an_RGB_Sequence_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.16193)] [[paper with code](https://paperswithcode.com/paper/in-hand-3d-object-scanning-from-an-rgb)]

- AutoRecon: Automated 3D Object Discovery and Reconstruction [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_AutoRecon_Automated_3D_Object_Discovery_and_Reconstruction_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.08810)] [[paper with code](https://paperswithcode.com/paper/autorecon-automated-3d-object-discovery-and)]

- NeuralLift-360: Lifting an In-the-Wild 2D Photo to a 3D Object With 360deg Views [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/neurallift-360-lifting-an-in-the-wild-2d-1)]

- gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_gSDF_Geometry-Driven_Signed_Distance_Functions_for_3D_Hand-Object_Reconstruction_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.11970)] [[paper with code](https://paperswithcode.com/paper/gsdf-geometry-driven-signed-distance)]

- Fantastic Breaks: A Dataset of Paired 3D Scans of Real-World Broken Objects and Their Complete Counterparts [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Lamb_Fantastic_Breaks_A_Dataset_of_Paired_3D_Scans_of_Real-World_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.14152)] [[paper with code](https://paperswithcode.com/paper/fantastic-breaks-a-dataset-of-paired-3d-scans)]


## ICLR-2023


- Unsupervised 3D Object Learning through Neuron Activity aware Plasticity [[paper](https://iclr.cc/virtual/2023/poster/11282)] [[arxiv](https://arxiv.org/abs/2302.11622)] [[paper with code](https://paperswithcode.com/paper/unsupervised-3d-object-learning-through)] [[openreview](https://openreview.net/forum?id=mXPoBtnpMnuy)]


## ICCV-2023


- Vox-E: Text-Guided Voxel Editing of 3D Objects [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.12048)] [[paper with code](https://paperswithcode.com/paper/vox-e-text-guided-voxel-editing-of-3d-objects)] [[code](https://github.com/TAU-VAILab/Vox-E)]

- EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.06969)] [[paper with code](https://paperswithcode.com/paper/localizing-objects-in-3d-from-egocentric)] [[code](https://github.com/wayne-mai/egoloc)]

- NCHO: Unsupervised Learning for Neural 3D Composition of Humans and Objects [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.14345)] [[paper with code](https://paperswithcode.com/paper/ncho-unsupervised-learning-for-neural-3d)] [[code](https://github.com/taeksuu/ncho)]

- ATT3D: Amortized Text-to-3D Object Synthesis [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2306.07349)] [[paper with code](https://paperswithcode.com/paper/att3d-amortized-text-to-3d-object-synthesis)]

- Understanding 3D Object Interaction from a Single Image [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.09664)] [[paper with code](https://paperswithcode.com/paper/understanding-3d-object-interaction-from-a)] [[code](https://github.com/JasonQSY/3DOI)]

- Zero-1-to-3: Zero-shot One Image to 3D Object [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.11328)] [[paper with code](https://paperswithcode.com/paper/zero-1-to-3-zero-shot-one-image-to-3d-object)] [[code](https://github.com/cvlab-columbia/zero123)]

- MAAL: Multimodality-Aware Autoencoder-Based Affordance Learning for 3D Articulated Objects [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/maal-multimodality-aware-autoencoder-based)] [[code](https://github.com/akira-l/maal)]

- CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.12288)] [[paper with code](https://paperswithcode.com/paper/chorus-learning-canonicalized-3d-human-object-1)]

- AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2309.11170)] [[paper with code](https://paperswithcode.com/paper/autosynth-learning-to-generate-3d-training)]

- Grounding 3D Object Affordance from 2D Interactions in Images [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.10437)] [[paper with code](https://paperswithcode.com/paper/grounding-3d-object-affordance-from-2d)] [[code](https://github.com/yyvhang/iagnet)]

- InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.16905)] [[paper with code](https://paperswithcode.com/paper/interdiff-generating-3d-human-object)] [[code](https://github.com/Sirui-Xu/InterDiff)]

- GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2310.20319)] [[paper with code](https://paperswithcode.com/paper/gace-geometry-aware-confidence-enhancement-1)] [[code](https://github.com/dschinagl/gace)]

- Multi3DRefer: Grounding Text Description to Multiple 3D Objects [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2309.05251)] [[paper with code](https://paperswithcode.com/paper/multi3drefer-grounding-text-description-to)]

- DPF-Net: Combining Explicit Shape Priors in Deformable Primitive Field for Unsupervised Structural Reconstruction of 3D Objects [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.13225)] [[paper with code](https://paperswithcode.com/paper/dpf-net-combining-explicit-shape-priors-in)]

- Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.00967)] [[paper with code](https://paperswithcode.com/paper/temporal-enhanced-training-of-multi-view-3d)] [[code](https://github.com/sense-x/hop)]

- Iterative Superquadric Recomposition of 3D Objects from Multiple Views [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2309.02102)] [[paper with code](https://paperswithcode.com/paper/iterative-superquadric-recomposition-of-3d)] [[code](https://github.com/explainableml/isco)]


## IJCAI-2023


- Contact2Grasp: 3D Grasp Synthesis via Hand-Object Contact Constraint [[paper](https://www.ijcai.org/proceedings/2023/117)] [[arxiv](https://arxiv.org/abs/2210.09245)] [[paper with code](https://paperswithcode.com/paper/learning-object-affordance-with-contact-and)]


## AAAI-2023


- 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25186)] [[arxiv](https://arxiv.org/abs/2212.01103)] [[paper with code](https://paperswithcode.com/paper/3d-togo-towards-text-guided-cross-category-3d)]

- Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25344)]



# 2022


## NeurIPS-2022


- MultiScan: Scalable RGBD scanning for 3D environments with articulated objects [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b3a83a5d86e1d424daefed43d998079-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=YxUdazpgweG)]

- Language Conditioned Spatial Relation Reasoning for 3D Object Grounding [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/819aaee144cb40e887a4aa9e781b1547-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2211.09646)] [[paper with code](https://paperswithcode.com/paper/language-conditioned-spatial-relation)] [[code](https://github.com/cshizhe/vil3dref)] [[openreview](https://openreview.net/forum?id=8li9SYYY3eQ)]

- OGC: Unsupervised 3D Object Segmentation from Rigid Dynamics of Point Clouds [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/c6e3856954d23bec921f2d13d8c0e0e7-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.04458)] [[paper with code](https://paperswithcode.com/paper/ogc-unsupervised-3d-object-segmentation-from)] [[code](https://github.com/vlar-group/ogc)] [[openreview](https://openreview.net/forum?id=ecNbEOOtqBU)]


## CVPR-2022


- HyperDet3D: Learning a Scene-Conditioned 3D Object Detector [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2204.05599)] [[paper with code](https://paperswithcode.com/paper/hyperdet3d-learning-a-scene-conditioned-3d)]

- KeyTr: Keypoint Transporter for 3D Reconstruction of Deformable Objects in Videos [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.html)] [[paper with code](https://paperswithcode.com/paper/keytr-keypoint-transporter-for-3d)]

- De-Rendering 3D Objects in the Wild [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2201.02279)] [[paper with code](https://paperswithcode.com/paper/de-rendering-3d-objects-in-the-wild)] [[code](https://github.com/brummi/derender3d)]

- ABO: Dataset and Benchmarks for Real-World 3D Object Understanding [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2110.06199)] [[paper with code](https://paperswithcode.com/paper/abo-dataset-and-benchmarks-for-real-world-3d)] [[code](https://github.com/jazcollins/amazon-berkeley-objects)]

- Point2Seq: Detecting 3D Objects As Sequences [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.13394)] [[paper with code](https://paperswithcode.com/paper/point2seq-detecting-3d-objects-as-sequences)] [[code](https://github.com/ocnflag/point2seq)]

- ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2109.05488)] [[paper with code](https://paperswithcode.com/paper/artiboost-boosting-articulated-3d-hand-object)] [[code](https://github.com/mvig-sjtu/artiboost)]

- Point2Cyl: Reverse Engineering 3D Objects From Point Clouds to Extrusion Cylinders [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.09329)] [[paper with code](https://paperswithcode.com/paper/point2cyl-reverse-engineering-3d-objects-from)]

- Embracing Single Stride 3D Object Detector With Sparse Transformer [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.06375)] [[paper with code](https://paperswithcode.com/paper/embracing-single-stride-3d-object-detector)] [[code](https://github.com/tusimple/sst)]

- Motion-From-Blur: 3D Shape and Motion Estimation of Motion-Blurred Objects in Videos [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2111.14465)] [[paper with code](https://paperswithcode.com/paper/motion-from-blur-3d-shape-and-motion)] [[code](https://github.com/rozumden/motionfromblur)]

- Learning 3D Object Shape and Layout Without 3D Supervision [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.07028)] [[paper with code](https://paperswithcode.com/paper/learning-3d-object-shape-and-layout-without-1)]

- Primitive3D: 3D Object Dataset Synthesis From Randomly Assembled Primitives [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2205.12627)] [[paper with code](https://paperswithcode.com/paper/primitive3d-3d-object-dataset-synthesis-from)]

- OccAM's Laser: Occlusion-Based Attribution Maps for 3D Object Detectors on LiDAR Data [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2204.06577)] [[paper with code](https://paperswithcode.com/paper/occam-s-laser-occlusion-based-attribution)] [[code](https://github.com/dschinagl/occam)]

- Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.17234)] [[paper with code](https://paperswithcode.com/paper/templates-for-3d-object-pose-estimation)] [[code](https://github.com/nv-nguyen/template-pose)]

- Understanding 3D Object Articulation in Internet Videos [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.16531)] [[paper with code](https://paperswithcode.com/paper/understanding-3d-object-articulation-in)]

- What's in Your Hands? 3D Reconstruction of Generic Objects in Hands [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.html)] [[paper with code](https://paperswithcode.com/paper/what-s-in-your-hands-3d-reconstruction-of)] [[code](https://github.com/judyye/ihoi)]

- Watch It Move: Unsupervised Discovery of 3D Joints for Re-Posing of Articulated Objects [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.11347)] [[paper with code](https://paperswithcode.com/paper/watch-it-move-unsupervised-discovery-of-3d)] [[code](https://github.com/nvlabs/watch-it-move)]

- AutoRF: Learning 3D Object Radiance Fields From Single View Observations [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2204.03593)] [[paper with code](https://paperswithcode.com/paper/autorf-learning-3d-object-radiance-fields)]

- Keypoint Transformer: Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2104.14639)] [[paper with code](https://paperswithcode.com/paper/handsformer-keypoint-transformer-for)] [[code](https://github.com/shreyashampali/kypt_transformer)]

- MonoGround: Detecting Monocular 3D Objects From the Ground [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.07372)] [[paper with code](https://paperswithcode.com/paper/monoground-detecting-monocular-3d-objects-1)] [[code](https://github.com/cfzd/monoground)]


## ICLR-2022


- IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes [[paper](https://iclr.cc/virtual/2022/poster/6870)] [[arxiv](https://arxiv.org/abs/2112.05298)] [[paper with code](https://paperswithcode.com/paper/ifr-explore-learning-inter-object-functional-1)] [[openreview](https://openreview.net/forum?id=OT3mLgR8Wg8)]

- VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects [[paper](https://iclr.cc/virtual/2022/poster/6298)] [[arxiv](https://arxiv.org/abs/2106.14440)] [[paper with code](https://paperswithcode.com/paper/vat-mart-learning-visual-action-trajectory)] [[openreview](https://openreview.net/forum?id=iEx3PiooLy)]


## ECCV-2022


- Fusing Local Similarities for Retrieval-Based 3D Orientation Estimation of Unseen Objects [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/444_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2203.08472)] [[paper with code](https://paperswithcode.com/paper/fusing-local-similarities-for-retrieval-based)]

- S2Contact: Graph-Based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3351_ECCV_2022_paper.php)]

- Monocular 3D Object Reconstruction with GAN Inversion [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3999_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.10061)] [[paper with code](https://paperswithcode.com/paper/monocular-3d-object-reconstruction-with-gan)] [[code](https://github.com/junzhezhang/mesh-inversion)]

- Object Wake-Up: 3D Object Rigging from a Single Image [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5901_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2108.02708)] [[paper with code](https://paperswithcode.com/paper/object-wake-up-3-d-object-reconstruction)]

- Label-Guided Auxiliary Training Improves 3D Object Detector [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3921_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.11753)] [[paper with code](https://paperswithcode.com/paper/label-guided-auxiliary-training-improves-3d)] [[code](https://github.com/fabiencode/lg3d)]

- RayTran: 3D Pose Estimation and Shape Reconstruction of Multiple Objects from Videos with Ray-Traced Transformers [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5669_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2203.13296)] [[paper with code](https://paperswithcode.com/paper/raytran-3d-pose-estimation-and-shape)]

- Few-Shot Class-Incremental Learning for 3D Point Cloud Objects [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3641_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2205.15225)] [[paper with code](https://paperswithcode.com/paper/few-shot-class-incremental-learning-for-3d)] [[code](https://github.com/townim-faisal/fscil-3d)]

- Spatially Invariant Unsupervised 3D Object-Centric Learning and Scene Decomposition [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4019_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2106.05607)] [[paper with code](https://paperswithcode.com/paper/spatially-invariant-unsupervised-3d-object)]

- AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-Shot Interactions [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/1730_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2112.00246)] [[paper with code](https://paperswithcode.com/paper/adaafford-learning-to-adapt-manipulation)]


# 2021


## NeurIPS-2021


- Unsupervised Object-Based Transition Models For 3D Partially Observable Environments [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/e5841df2166dd424a57127423d276bbe-Abstract.html)] [[arxiv](https://arxiv.org/abs/2103.04693)] [[paper with code](https://paperswithcode.com/paper/unsupervised-object-based-transition-models)] [[openreview](https://openreview.net/forum?id=X17EOUP2Cgt)]

- Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/fb60d411a5c5b72b2e7d3527cfc84fd0-Abstract.html)] [[arxiv](https://arxiv.org/abs/2106.08762)] [[paper with code](https://paperswithcode.com/paper/shape-from-blur-recovering-textured-3d-shape)] [[code](https://github.com/rozumden/ShapeFromBlur)] [[openreview](https://openreview.net/forum?id=CyZF4CLnQ8D)]


## CVPR-2021


- From Points to Multi-Object 3D Reconstruction [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Engelmann_From_Points_to_Multi-Object_3D_Reconstruction_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2012.11575)]

- M3DSSD: Monocular 3D Single Stage Object Detector [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Luo_M3DSSD_Monocular_3D_Single_Stage_Object_Detector_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.13164)] [[paper with code](https://paperswithcode.com/paper/m3dssd-monocular-3d-single-stage-object)] [[code](https://github.com/mumianyuxin/M3DSSD)]

- 3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.16397)] [[paper with code](https://paperswithcode.com/paper/3d-affordancenet-a-benchmark-for-visual)] [[code](https://github.com/Gorilla-Lab-SCUT/AffordanceNet)]

- Unsupervised Learning of 3D Object Categories From Videos in the Wild [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Henzler_Unsupervised_Learning_of_3D_Object_Categories_From_Videos_in_the_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.16552)] [[paper with code](https://paperswithcode.com/paper/unsupervised-learning-of-3d-object-categories)]

- Semi-Supervised 3D Hand-Object Poses Estimation With Interactions in Time [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2106.05266)] [[paper with code](https://paperswithcode.com/paper/semi-supervised-3d-hand-object-poses)]

- PVGNet: A Bottom-Up One-Stage 3D Object Detector With Integrated Multi-Level Features [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Miao_PVGNet_A_Bottom-Up_One-Stage_3D_Object_Detector_With_Integrated_Multi-Level_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/pvgnet-a-bottom-up-one-stage-3d-object)]

- LiDAR R-CNN: An Efficient and Universal 3D Object Detector [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Li_LiDAR_R-CNN_An_Efficient_and_Universal_3D_Object_Detector_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.15297)] [[paper with code](https://paperswithcode.com/paper/lidar-r-cnn-an-efficient-and-universal-3d)] [[code](https://github.com/tusimple/LiDAR_RCNN)]

- RangeIoUDet: Range Image Based Real-Time 3D Object Detector Optimized by Intersection Over Union [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Liang_RangeIoUDet_Range_Image_Based_Real-Time_3D_Object_Detector_Optimized_by_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/rangeioudet-range-image-based-real-time-3d)]

- Single-View 3D Object Reconstruction From Shape Priors in Memory [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Single-View_3D_Object_Reconstruction_From_Shape_Priors_in_Memory_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2003.03711)] [[paper with code](https://paperswithcode.com/paper/meta3d-single-view-3d-object-reconstruction)]


## ICLR-2021


- Unsupervised Discovery of 3D Physical Objects [[paper](https://iclr.cc/virtual/2021/poster/3207)] [[arxiv](https://arxiv.org/abs/2007.12348)] [[paper with code](https://paperswithcode.com/paper/unsupervised-discovery-of-3d-physical-objects-1)] [[openreview](https://openreview.net/forum?id=lf7st0bJIA5)]


## ICCV-2021


- Gravity-Aware Monocular 3D Human-Object Reconstruction [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Dabral_Gravity-Aware_Monocular_3D_Human-Object_Reconstruction_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.08844)] [[paper with code](https://paperswithcode.com/paper/gravity-aware-monocular-3d-human-object)]

- Where2Act: From Pixels to Actions for Articulated 3D Objects [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Mo_Where2Act_From_Pixels_to_Actions_for_Articulated_3D_Objects_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2101.02692)] [[paper with code](https://paperswithcode.com/paper/where2act-from-pixels-to-actions-for)] [[code](https://github.com/daerduoCarey/where2act)]

- Free-Form Description Guided 3D Visual Graph Network for Object Grounding in Point Cloud [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Feng_Free-Form_Description_Guided_3D_Visual_Graph_Network_for_Object_Grounding_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.16381)] [[paper with code](https://paperswithcode.com/paper/free-form-description-guided-3d-visual-graph)] [[code](https://github.com/PNXD/FFL-3DOG)]

- DensePose 3D: Lifting Canonical Surface Maps of Articulated Objects to the Third Dimension [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Shapovalov_DensePose_3D_Lifting_Canonical_Surface_Maps_of_Articulated_Objects_to_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2109.00033)] [[paper with code](https://paperswithcode.com/paper/densepose-3d-lifting-canonical-surface-maps)]

- Holistic Pose Graph: Modeling Geometric Structure Among Objects in a Scene Using Graph Inference for 3D Object Prediction [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Xiao_Holistic_Pose_Graph_Modeling_Geometric_Structure_Among_Objects_in_a_ICCV_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/holistic-pose-graph-modeling-geometric)]

- Common Objects in 3D: Large-Scale Learning and Evaluation of Real-Life 3D Category Reconstruction [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Reizenstein_Common_Objects_in_3D_Large-Scale_Learning_and_Evaluation_of_Real-Life_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2109.00512)] [[paper with code](https://paperswithcode.com/paper/common-objects-in-3d-large-scale-learning-and)] [[code](https://github.com/facebookresearch/co3d)]

- Toward Realistic Single-View 3D Object Reconstruction With Unsupervised Learning From Multiple Images [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Ho_Toward_Realistic_Single-View_3D_Object_Reconstruction_With_Unsupervised_Learning_From_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2109.02288)] [[paper with code](https://paperswithcode.com/paper/toward-realistic-single-view-3d-object)] [[code](https://github.com/vinairesearch/lemul)]

- Learning Canonical 3D Object Representation for Fine-Grained Recognition [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Joung_Learning_Canonical_3D_Object_Representation_for_Fine-Grained_Recognition_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.04628)] [[paper with code](https://paperswithcode.com/paper/learning-canonical-3d-object-representation)]


## IJCAI-2021


- Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in a First-person Simulated 3D Environment [[paper](https://www.ijcai.org/proceedings/2021/306)] [[arxiv](https://arxiv.org/abs/2010.15195)] [[paper with code](https://paperswithcode.com/paper/reinforcement-learning-for-sparse-reward-1)]

- Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild (Extended Abstract) [[paper](https://www.ijcai.org/proceedings/2021/665)]


## AAAI-2021


- Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16414)] [[arxiv](https://arxiv.org/abs/2012.10921)] [[paper with code](https://paperswithcode.com/paper/learning-geometry-disentangled-representation)] [[code](https://github.com/mutianxu/GDANet)]

- R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16426)] [[arxiv](https://arxiv.org/abs/1908.05612)] [[paper with code](https://paperswithcode.com/paper/r3det-refined-single-stage-detector-with)] [[code](https://github.com/yangxue0827/RotationDetection)]

- I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16756)] [[arxiv](https://arxiv.org/abs/2012.09014)] [[paper with code](https://paperswithcode.com/paper/i3dol-incremental-3d-object-learning-without)]



# 2020


## NeurIPS-2020


- Unsupervised object-centric video generation and decomposition in 3D [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/20125fd9b2d43e340a35fb0278da235d-Abstract.html)] [[arxiv](https://arxiv.org/abs/2007.06705)] [[paper with code](https://paperswithcode.com/paper/unsupervised-object-centric-video-generation)] [[code](https://github.com/pmh47/o3v)]

- BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/4b29fa4efe4fb7bc667c7b301b74d52d-Abstract.html)] [[arxiv](https://arxiv.org/abs/2002.08988)] [[paper with code](https://paperswithcode.com/paper/blockgan-learning-3d-object-aware-scene)] [[code](https://github.com/thunguyenphuoc/BlockGAN)]

- SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html)] [[arxiv](https://arxiv.org/abs/2010.10505)] [[paper with code](https://paperswithcode.com/paper/sdf-srn-learning-signed-distance-3d-object)] [[code](https://github.com/chenhsuanlin/signed-distance-SRN)]


## CVPR-2020


- Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes From a Single Image [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Nie_Total3DUnderstanding_Joint_Layout_Object_Pose_and_Mesh_Reconstruction_for_Indoor_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2002.12212)] [[paper with code](https://paperswithcode.com/paper/total3dunderstanding-joint-layout-object-pose)] [[code](https://github.com/yinyunie/Total3DUnderstanding)]

- Learning Unsupervised Hierarchical Part Decomposition of 3D Objects From a Single RGB Image [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Paschalidou_Learning_Unsupervised_Hierarchical_Part_Decomposition_of_3D_Objects_From_a_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.01176)] [[paper with code](https://paperswithcode.com/paper/learning-unsupervised-hierarchical-part)] [[code](https://github.com/paschalidoud/hierarchical_primitives)]

- HOnnotate: A Method for 3D Annotation of Hand and Object Poses [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Hampali_HOnnotate_A_Method_for_3D_Annotation_of_Hand_and_Object_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1907.01481)] [[paper with code](https://paperswithcode.com/paper/ho-3d-a-multi-user-multi-object-dataset-for)] [[code](https://github.com/shreyashampali/ho3d)]

- Unsupervised Learning of Probably Symmetric Deformable 3D Objects From Images in the Wild [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Wu_Unsupervised_Learning_of_Probably_Symmetric_Deformable_3D_Objects_From_Images_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1911.11130)] [[paper with code](https://paperswithcode.com/paper/unsupervised-learning-of-probably-symmetric)] [[code](https://github.com/elliottwu/unsup3d)]

- Weakly-Supervised Domain Adaptation via GAN and Mesh Model for Estimating 3D Hand Poses Interacting Objects [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Baek_Weakly-Supervised_Domain_Adaptation_via_GAN_and_Mesh_Model_for_Estimating_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/weakly-supervised-domain-adaptation-via-gan)]

- Connect-and-Slice: An Hybrid Approach for Reconstructing 3D Objects [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Fang_Connect-and-Slice_An_Hybrid_Approach_for_Reconstructing_3D_Objects_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/connect-and-slice-an-hybrid-approach-for)]

- DOPS: Learning to Detect 3D Objects and Predict Their 3D Shapes [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Najibi_DOPS_Learning_to_Detect_3D_Objects_and_Predict_Their_3D_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.01170)] [[paper with code](https://paperswithcode.com/paper/dops-learning-to-detect-3d-objects-and)]

- Detailed 2D-3D Joint Representation for Human-Object Interaction [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Detailed_2D-3D_Joint_Representation_for_Human-Object_Interaction_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.08154)] [[paper with code](https://paperswithcode.com/paper/detailed-2d-3d-joint-representation-for-human)] [[code](https://github.com/DirtyHarryLYL/DJ-RN)]

- Learning Deep Network for Detecting 3D Object Keypoints and 6D Poses [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Zhao_Learning_Deep_Network_for_Detecting_3D_Object_Keypoints_and_6D_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-deep-network-for-detecting-3d-object)]

- Train in Germany, Test in the USA: Making 3D Object Detectors Generalize [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Train_in_Germany_Test_in_the_USA_Making_3D_Object_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2005.08139)] [[paper with code](https://paperswithcode.com/paper/train-in-germany-test-in-the-usa-making-3d)] [[code](https://github.com/cxy1997/3D_adapt_auto_driving)]

- KeyPose: Multi-View 3D Labeling and Keypoint Estimation for Transparent Objects [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_KeyPose_Multi-View_3D_Labeling_and_Keypoint_Estimation_for_Transparent_Objects_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1912.02805)] [[paper with code](https://paperswithcode.com/paper/keypose-multi-view-3d-labeling-and-keypoint)] [[code](https://github.com/google-research/google-research/tree/master/keypose)]

- 3D Part Guided Image Editing for Fine-Grained Object Understanding [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_3D_Part_Guided_Image_Editing_for_Fine-Grained_Object_Understanding_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/3d-part-guided-image-editing-for-fine-grained)] [[code](https://github.com/zongdai/EditingForDNN)]

- 3DSSD: Point-Based 3D Single Stage Object Detector [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Yang_3DSSD_Point-Based_3D_Single_Stage_Object_Detector_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2002.10187)] [[paper with code](https://paperswithcode.com/paper/3dssd-point-based-3d-single-stage-object)] [[code](https://github.com/open-mmlab/mmdetection3d)]

- Autolabeling 3D Objects With Differentiable Rendering of SDF Shape Priors [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Zakharov_Autolabeling_3D_Objects_With_Differentiable_Rendering_of_SDF_Shape_Priors_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1911.11288)] [[paper with code](https://paperswithcode.com/paper/autolabeling-3d-objects-with-differentiable)] [[code](https://github.com/TRI-ML/sdflabel)]



## ICLR-2020


- Higher-Order Function Networks for Learning Composable 3D Object Representations [[paper](https://iclr.cc/virtual/2020/poster/1427)] [[arxiv](https://arxiv.org/abs/1907.10388)] [[paper with code](https://paperswithcode.com/paper/higher-order-function-networks-for-learning)] [[openreview](https://openreview.net/forum?id=HJgfDREKDB)]


## ECCV-2020


- ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/1501_ECCV_2020_paper.php)]

- Perceiving 3D Human-Object Spatial Arrangements from a Single Image in the Wild [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/1474_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2007.15649)]

- Interactive Annotation of 3D Object Geometry using 2D Scribbles [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2888_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2008.10719)]

- Pix2Surf: Learning Parametric 3D Surface Models of Objects from Images [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2941_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2008.07760)]

- Unsupervised Multi-View CNN for Salient View Selection of 3D Objects and Scenes [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3254_ECCV_2020_paper.php)]

- ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3408_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/1912.08830)]

- Human Correspondence Consensus for 3D Object Semantic Understanding [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/4107_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/1912.12577)]

- Measuring Generalisation to Unseen Viewpoints, Articulations, Shapes and Objects for 3D Hand Pose Estimation under Hand-Object Interaction [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/4220_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2003.13764)]

- Efficient Outdoor 3D Point Cloud Semantic Segmentation for Critical Road Objects and Distributed Contexts [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5831_ECCV_2020_paper.php)]

- Procrustean Regression Networks: Learning 3D Structure of Non-Rigid Objects from 2D Annotations [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/6446_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2007.10961)]

- Info3D: Representation Learning on 3D Objects using Mutual Information Maximization and Contrastive Learning [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/6884_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2006.02598)]


## ICML-2020


- MoNet3D: Towards Accurate Monocular 3D Object Localization in Real Time [[paper](https://proceedings.mlr.press/v119/zhou20b.html)] [[arxiv](https://arxiv.org/abs/2006.16007)] [[paper with code](https://paperswithcode.com/paper/monet3d-towards-accurate-monocular-3d-object)] [[code](https://github.com/CQUlearningsystemgroup/YicongPeng)]


## IJCAI-2020


- A 3D Convolutional Approach to Spectral Object Segmentation in Space and Time [[paper](https://www.ijcai.org/proceedings/2020/69)] [[arxiv](https://arxiv.org/abs/1907.02731)] [[paper with code](https://paperswithcode.com/paper/a-spectral-approach-to-unsupervised-object)] [[code](https://github.com/bit-ml/sfseg)]

- Consistent Domain Structure Learning and Domain Alignment for 2D Image-Based 3D Objects Retrieval [[paper](https://www.ijcai.org/proceedings/2020/123)]

- Joint Multi-view 2D Convolutional Neural Networks for 3D Object Classification [[paper](https://www.ijcai.org/proceedings/2020/443)]


## AAAI-2020


- Synthetic Depth Transfer for Monocular 3D Object Pose Estimation in the Wild [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6781)]

- PI-RCNN: An Efficient Multi-Sensor 3D Object Detector with Point-Based Attentive Cont-Conv Fusion Module [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6933)] [[arxiv](https://arxiv.org/abs/1911.06084)] [[paper with code](https://paperswithcode.com/paper/pi-rcnn-an-efficient-multi-sensor-3d-object)]



# 2019


## NeurIPS-2019


- Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/d0aa518d4d3bfc721aa0b8ab4ef32269-Abstract.html)] [[arxiv](https://arxiv.org/abs/1906.01140)] [[paper with code](https://paperswithcode.com/paper/learning-object-bounding-boxes-for-3d)] [[code](https://github.com/Yang7879/3D-BoNet)]

- Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/f5ac21cd0ef1b88e9848571aeb53551a-Abstract.html)] [[arxiv](https://arxiv.org/abs/1908.01210)] [[paper with code](https://paperswithcode.com/paper/learning-to-predict-3d-objects-with-an)] [[code](https://github.com/nv-tlabs/DIB-R)]


## CVPR-2019


- PartNet: A Large-Scale Benchmark for Fine-Grained and Hierarchical Part-Level 3D Object Understanding [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Mo_PartNet_A_Large-Scale_Benchmark_for_Fine-Grained_and_Hierarchical_Part-Level_3D_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1812.02713)] [[paper with code](https://paperswithcode.com/paper/partnet-a-large-scale-benchmark-for-fine)] [[code](https://github.com/yangyanli/PointCNN)]

- Photometric Mesh Optimization for Video-Aligned 3D Object Reconstruction [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Photometric_Mesh_Optimization_for_Video-Aligned_3D_Object_Reconstruction_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1903.08642)] [[paper with code](https://paperswithcode.com/paper/photometric-mesh-optimization-for-video)] [[code](https://github.com/chenhsuanlin/photometric-mesh-optim)]

- H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Tekin_HO_Unified_Egocentric_Recognition_of_3D_Hand-Object_Poses_and_Interactions_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.05349)] [[paper with code](https://paperswithcode.com/paper/ho-unified-egocentric-recognition-of-3d-hand)] [[code](https://github.com/shashwat14/UnifiedPoseEstimation)]

- Estimating 3D Motion and Forces of Person-Object Interactions From Monocular Video [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Estimating_3D_Motion_and_Forces_of_Person-Object_Interactions_From_Monocular_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.02683)] [[paper with code](https://paperswithcode.com/paper/estimating-3d-motion-and-forces-of-person)] [[code](https://github.com/ManifoldFR/recvis-project)]

- LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Meyer_LaserNet_An_Efficient_Probabilistic_3D_Object_Detector_for_Autonomous_Driving_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1903.08701)] [[paper with code](https://paperswithcode.com/paper/lasernet-an-efficient-probabilistic-3d-object)]


## ICCV-2019


- STD: Sparse-to-Dense 3D Object Detector for Point Cloud [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Yang_STD_Sparse-to-Dense_3D_Object_Detector_for_Point_Cloud_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1907.10471)] [[paper with code](https://paperswithcode.com/paper/std-sparse-to-dense-3d-object-detector-for)]

- 3D-RelNet: Joint Object and Relational Network for 3D Prediction [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Kulkarni_3D-RelNet_Joint_Object_and_Relational_Network_for_3D_Prediction_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1906.02729)] [[paper with code](https://paperswithcode.com/paper/3d-relnet-joint-object-and-relational-network-1)]

- Learning Relationships for Multi-View 3D Object Recognition [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Yang_Learning_Relationships_for_Multi-View_3D_Object_Recognition_ICCV_2019_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-relationships-for-multi-view-3d)]

- View N-Gram Network for 3D Object Retrieval [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/He_View_N-Gram_Network_for_3D_Object_Retrieval_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1908.01958)] [[paper with code](https://paperswithcode.com/paper/view-n-gram-network-for-3d-object-retrieval)]

- RIO: 3D Object Instance Re-Localization in Changing Indoor Environments [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Wald_RIO_3D_Object_Instance_Re-Localization_in_Changing_Indoor_Environments_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1908.06109)] [[paper with code](https://paperswithcode.com/paper/rio-3d-object-instance-re-localization-in)] [[code](https://github.com/WaldJohannaU/3RScan)]

- Holistic++ Scene Understanding: Single-View 3D Holistic Scene Parsing and Human Pose Estimation With Human-Object Interaction and Physical Commonsense [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Chen_Holistic_Scene_Understanding_Single-View_3D_Holistic_Scene_Parsing_and_Human_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1909.01507)] [[paper with code](https://paperswithcode.com/paper/holistic-scene-understanding-single-view-3d)]

- Joint Embedding of 3D Scan and CAD Objects [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Dahnert_Joint_Embedding_of_3D_Scan_and_CAD_Objects_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1908.06989)] [[paper with code](https://paperswithcode.com/paper/joint-embedding-of-3d-scan-and-cad-objects)] [[code](https://github.com/xheon/JointEmbedding)]


## IJCAI-2019


- MAT-Net: Medial Axis Transform Network for 3D Object Recognition [[paper](https://www.ijcai.org/proceedings/2019/109)]


## AAAI-2019


- DeepCCFV: Camera Constraint-Free Multi-View Convolutional Neural Network for 3D Object Retrieval [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4868)]

- MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4912)] [[arxiv](https://arxiv.org/abs/1811.10247)] [[paper with code](https://paperswithcode.com/paper/monogrnet-a-geometric-reasoning-network-for)] [[code](https://github.com/Zengyi-Qin/MonoGRNet)]

- Deep Single-View 3D Object Reconstruction with Visual Hull Embedding [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4922)] [[arxiv](https://arxiv.org/abs/1809.03451)] [[paper with code](https://paperswithcode.com/paper/deep-single-view-3d-object-reconstruction)] [[code](https://github.com/qweas120/PSVH-3d-reconstruction)]

- MVPNet: Multi-View Point Regression Networks for 3D Object Reconstruction from A Single Image [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4923)] [[arxiv](https://arxiv.org/abs/1811.09410)] [[paper with code](https://paperswithcode.com/paper/mvpnet-multi-view-point-regression-networks)]



# 2018


## NeurIPS-2018


- Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/39ae2ed11b14a4ccb41d35e9d1ba5d11-Abstract.html)] [[arxiv](https://arxiv.org/abs/1802.09987)] [[paper with code](https://paperswithcode.com/paper/multi-view-silhouette-and-depth-decomposition)] [[code](https://github.com/EdwardSmith1884/3D-Object-Super-Resolution)]

- Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/82161242827b703e6acf9c726942a1e4-Abstract.html)] [[arxiv](https://arxiv.org/abs/1810.13049)] [[paper with code](https://paperswithcode.com/paper/cooperative-holistic-scene-understanding)] [[code](https://github.com/thusiyuan/cooperative_scene_parsing)]

- Visual Object Networks: Image Generation with Disentangled 3D Representations [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/92cc227532d17e56e07902b254dfad10-Abstract.html)] [[arxiv](https://arxiv.org/abs/1812.02725)] [[paper with code](https://paperswithcode.com/paper/visual-object-networks-image-generation-with-1)] [[code](https://github.com/junyanz/VON)]


## CVPR-2018


- Multi-View Harmonized Bilinear Network for 3D Object Recognition [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.html)] [[paper with code](https://paperswithcode.com/paper/multi-view-harmonized-bilinear-network-for-3d)]

- Triplet-Center Loss for Multi-View 3D Object Retrieval [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1803.06189)] [[paper with code](https://paperswithcode.com/paper/triplet-center-loss-for-multi-view-3d-object)] [[code](https://github.com/popcornell/keras-triplet-center-loss)]

- 3D Pose Estimation and 3D Model Retrieval for Objects in the Wild [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Grabner_3D_Pose_Estimation_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1803.11493)] [[paper with code](https://paperswithcode.com/paper/3d-pose-estimation-and-3d-model-retrieval-for)]

- Pixels, Voxels, and Views: A Study of Shape Representations for Single View 3D Object Shape Prediction [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Shin_Pixels_Voxels_and_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1804.06032)] [[paper with code](https://paperswithcode.com/paper/pixels-voxels-and-views-a-study-of-shape)]

- 3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.html)] [[paper with code](https://paperswithcode.com/paper/3d-rcnn-instance-level-3d-object)]


## ECCV-2018


- GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Li_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.php)] [[paper with code](https://paperswithcode.com/paper/gal-geometric-adversarial-loss-for-single)]

- Making Deep Heatmaps Robust to Partial Occlusions for 3D Object Pose Estimation [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Markus_Oberweger_Making_Deep_Heatmaps_ECCV_2018_paper.php)] [[arxiv](https://arxiv.org/abs/1804.03959)] [[paper with code](https://paperswithcode.com/paper/making-deep-heatmaps-robust-to-partial)]


## IJCAI-2018


- 3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations [[paper](https://www.ijcai.org/proceedings/2018/688)] [[arxiv](https://arxiv.org/abs/1805.00328)] [[paper with code](https://paperswithcode.com/paper/3d-physnet-learning-the-intuitive-physics-of)] [[code](https://github.com/vividda/3D-PhysNet)]


## AAAI-2018


- Perceiving, Learning, and Recognizing 3D Objects: An Approach to Cognitive Service Robots [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/11319)]

- Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/12278)] [[arxiv](https://arxiv.org/abs/1706.07036)] [[paper with code](https://paperswithcode.com/paper/learning-efficient-point-cloud-generation-for)] [[code](https://github.com/chenhsuanlin/3D-point-cloud-generation)]

- Group-Pair Convolutional Neural Networks for Multi-View Based 3D Object Retrieval [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/11899)]