# Awesome 3D Object Tracking Paper Collection

- [2024](#2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [CVPR](#cvpr-2023)
  - [ICCV](#iccv-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [CVPR](#cvpr-2022)
  - [ECCV](#eccv-2022)
  - [AAAI](#aaai-2022)

- [2021](#2021)
  - [NeurIPS](#neurips-2021)
  - [CVPR](#cvpr-2021)
  - [ICCV](#iccv-2021)

- [2020](#2020)
  - [CVPR](#cvpr-2020)

- [2018](#2018)
  - [ECCV](#eccv-2018)



# 2024


## ICLR-2024


- Towards Category Unification of 3D Single Object Tracking on Point Clouds [[paper](https://iclr.cc/virtual/2024/poster/18670)] [[arxiv](https://arxiv.org/abs/2401.11204)] [[paper with code](https://paperswithcode.com/paper/towards-category-unification-of-3d-single)] [[openreview](https://openreview.net/forum?id=QlqdXrzzD1)]


## AAAI-2024


- M3SOT: Multi-Frame, Multi-Field, Multi-Space 3D Single Object Tracking [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28152)] [[arxiv](https://arxiv.org/abs/2312.06117)] [[paper with code](https://paperswithcode.com/paper/m3sot-multi-frame-multi-field-multi-space-3d)] [[code](https://github.com/ywu0912/teamcode)]

- Modeling Continuous Motion for 3D Point Cloud Object Tracking [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28196)] [[arxiv](https://arxiv.org/abs/2303.07605)] [[paper with code](https://paperswithcode.com/paper/modeling-continuous-motion-for-3d-point-cloud)]



# 2023


## CVPR-2023


- VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_VoxelNeXt_Fully_Sparse_VoxelNet_for_3D_Object_Detection_and_Tracking_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.11301)] [[paper with code](https://paperswithcode.com/paper/voxelnext-fully-sparse-voxelnet-for-3d-object-1)] [[code](https://github.com/dvlab-research/VoxelNeXt)]

- Standing Between Past and Future: Spatio-Temporal Modeling for Multi-Camera 3D Multi-Object Tracking [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Pang_Standing_Between_Past_and_Future_Spatio-Temporal_Modeling_for_Multi-Camera_3D_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2302.03802)] [[paper with code](https://paperswithcode.com/paper/standing-between-past-and-future-spatio)] [[code](https://github.com/tri-ml/pf-track)]

- BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wen_BundleSDF_Neural_6-DoF_Tracking_and_3D_Reconstruction_of_Unknown_Objects_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.14158)] [[paper with code](https://paperswithcode.com/paper/bundlesdf-neural-6-dof-tracking-and-3d)] [[code](https://github.com/NVlabs/BundleSDF)]


## ICCV-2023


- Tracking by 3D Model Estimation of Unknown Objects in Videos [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.06419)] [[paper with code](https://paperswithcode.com/paper/tracking-by-3d-model-estimation-of-unknown)]

- A Fast Unified System for 3D Object Detection and Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/a-fast-unified-system-for-3d-object-detection)] [[code](https://github.com/theitzin/fus3d)]

- MixCycle: Mixup Assisted Semi-Supervised 3D Single Object Tracking with Cycle Consistency [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.09219)] [[paper with code](https://paperswithcode.com/paper/mixcycle-mixup-assisted-semi-supervised-3d)] [[code](https://github.com/mumuqiao/mixcycle)]

- Delving into Motion-Aware Matching for Monocular 3D Object Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.11607)] [[paper with code](https://paperswithcode.com/paper/delving-into-motion-aware-matching-for)] [[code](https://github.com/kuanchihhuang/moma-m3t)]

- 3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.06635)] [[paper with code](https://paperswithcode.com/paper/3dmotformer-graph-transformer-for-online-3d)] [[code](https://github.com/dsx0511/3dmotformer)]

- TrajectoryFormer: 3D Object Tracking Transformer with Predictive Trajectory Hypotheses [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2306.05888)] [[paper with code](https://paperswithcode.com/paper/trajectoryformer-3d-object-tracking)] [[code](https://github.com/poodarchu/efg)]

- Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.12549)] [[paper with code](https://paperswithcode.com/paper/synchronize-feature-extracting-and-matching-a)]


## AAAI-2023


- GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25287)] [[arxiv](https://arxiv.org/abs/2211.10927)] [[paper with code](https://paperswithcode.com/paper/glt-t-global-local-transformer-voting-for-3d)] [[code](https://github.com/haooozi/glt-t)]



# 2022


## CVPR-2022


- Iterative Corresponding Geometry: Fusing Region and Depth for Highly Efficient 3D Tracking of Textureless Objects [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.05334)] [[paper with code](https://paperswithcode.com/paper/iterative-corresponding-geometry-fusing)] [[code](https://github.com/dlr-rm/3dobjecttracking)]

- BCOT: A Markerless High-Precision 3D Object Tracking Benchmark [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.13437)] [[paper with code](https://paperswithcode.com/paper/bcot-a-markerless-high-precision-3d-object)]

- Time3D: End-to-End Joint Monocular 3D Object Detection and Tracking for Autonomous Driving [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2205.14882)] [[paper with code](https://paperswithcode.com/paper/time3d-end-to-end-joint-monocular-3d-object)]

- PTTR: Relational 3D Point Cloud Object Tracking With Transformer [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.02857)] [[paper with code](https://paperswithcode.com/paper/pttr-relational-3d-point-cloud-object)] [[code](https://github.com/jasonkks/pttr)]

- Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.01730)] [[paper with code](https://paperswithcode.com/paper/beyond-3d-siamese-tracking-a-motion-centric)] [[code](https://github.com/ghostish/open3dsot)]


## ECCV-2022


- 3D Siamese Transformer Network for Single Object Tracking on Point Clouds [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5829_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.11995)] [[paper with code](https://paperswithcode.com/paper/3d-siamese-transformer-network-for-single)] [[code](https://github.com/fpthink/stnet)]

- PolarMOT: How Far Can Geometric Relations Take Us in 3D Multi-Object Tracking? [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/514_ECCV_2022_paper.php)] [[paper with code](https://paperswithcode.com/paper/polarmot-how-far-can-geometric-relations-take)]

- Large-Displacement 3D Object Tracking with Hybrid Non-local Optimization [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6742_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.12620)] [[paper with code](https://paperswithcode.com/paper/large-displacement-3d-object-tracking-with)] [[code](https://github.com/cvbubbles/nonlocal-3dtracking)]

- SpOT: Spatiotemporal Modeling for 3D Object Tracking [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/2657_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.05856)] [[paper with code](https://paperswithcode.com/paper/spot-spatiotemporal-modeling-for-3d-object)]


## AAAI-2022


- Joint 3D Object Detection and Tracking Using Spatio-Temporal Representation of Camera Image and LiDAR Point Clouds [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20007)] [[arxiv](https://arxiv.org/abs/2112.07116)] [[paper with code](https://paperswithcode.com/paper/joint-3d-object-detection-and-tracking-using)]

- Graph-Based Point Tracker for 3D Object Tracking in Point Clouds [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20101)]



# 2021


## NeurIPS-2021


- Sparse Steerable Convolutions: An Efficient Learning of SE(3)-Equivariant Features for Estimation and Tracking of Object Poses in 3D Space [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/8c1b6fa97c4288a4514365198566c6fa-Abstract.html)] [[arxiv](https://arxiv.org/abs/2111.07383)] [[paper with code](https://paperswithcode.com/paper/sparse-steerable-convolutions-an-efficient)] [[code](https://github.com/gorilla-lab-scut/ss-conv)] [[openreview](https://openreview.net/forum?id=RWYwTmP_BMZ)]


## CVPR-2021


- Center-Based 3D Object Detection and Tracking [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Center-Based_3D_Object_Detection_and_Tracking_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2006.11275)] [[paper with code](https://paperswithcode.com/paper/center-based-3d-object-detection-and-tracking)] [[code](https://github.com/tianweiy/CenterPoint)]

- Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Muller_Seeing_Behind_Objects_for_3D_Multi-Object_Tracking_in_RGB-D_Sequences_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2012.08197)] [[paper with code](https://paperswithcode.com/paper/seeing-behind-objects-for-3d-multi-object)]


## ICCV-2021


- Exploring Simple 3D Multi-Object Tracking for Autonomous Driving [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Luo_Exploring_Simple_3D_Multi-Object_Tracking_for_Autonomous_Driving_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.10312)] [[paper with code](https://paperswithcode.com/paper/exploring-simple-3d-multi-object-tracking-for)] [[code](https://github.com/qcraftai/simtrack)]

- You Don't Only Look Once: Constructing Spatial-Temporal Memory for Integrated 3D Object Detection and Tracking [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Sun_You_Dont_Only_Look_Once_Constructing_Spatial-Temporal_Memory_for_Integrated_ICCV_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/you-don-t-only-look-once-constructing-spatial)]



# 2020


## CVPR-2020


- Joint Spatial-Temporal Optimization for Stereo 3D Object Tracking [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Joint_Spatial-Temporal_Optimization_for_Stereo_3D_Object_Tracking_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.09305)] [[paper with code](https://paperswithcode.com/paper/joint-spatial-temporal-optimization-for)]

- P2B: Point-to-Box Network for 3D Object Tracking in Point Clouds [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Qi_P2B_Point-to-Box_Network_for_3D_Object_Tracking_in_Point_Clouds_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2005.13888)] [[paper with code](https://paperswithcode.com/paper/p2b-point-to-box-network-for-3d-object)] [[code](https://github.com/HaozheQi/P2B)]

- GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking With 2D-3D Multi-Feature Learning [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Weng_GNN3DMOT_Graph_Neural_Network_for_3D_Multi-Object_Tracking_With_2D-3D_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/gnn3dmot-graph-neural-network-for-3d-multi)] [[code](https://github.com/xinshuoweng/GNN3DMOT)]



# 2018


## ECCV-2018


- Stereo Vision-based Semantic 3D Object and Ego-motion Tracking for Autonomous Driving [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Peiliang_LI_Stereo_Vision-based_Semantic_ECCV_2018_paper.php)] [[arxiv](https://arxiv.org/abs/1807.02062)] [[paper with code](https://paperswithcode.com/paper/stereo-vision-based-semantic-3d-object-and)]

- Joint 3D tracking of a deformable object in interaction with a hand [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Aggeliki_Tsoli_Joint_3D_tracking_ECCV_2018_paper.php)] [[paper with code](https://paperswithcode.com/paper/joint-3d-tracking-of-a-deformable-object-in)]

- Combining 3D Model Contour Energy and Keypoints for Object Tracking [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Bogdan_Bugaev_Combining_3D_Model_ECCV_2018_paper.php)] [[arxiv](https://arxiv.org/abs/2002.01379)] [[paper with code](https://paperswithcode.com/paper/combining-3d-model-contour-energy-and-1)]