# Awesome 3D Generation Paper Collection

- [2024](#2024)
  - [CVPR](#cvpr-2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICLR](#iclr-2023)
  - [ICCV](#iccv-2023)
  - [ICML](#icml-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [CVPR](#cvpr-2022)
  - [ICLR](#iclr-2022)
  - [ECCV](#eccv-2022)
  - [ICML](#icml-2022)
  - [AAAI](#aaai-2022)

- [2021](#2021)
  - [NeurIPS](#neurips-2021)
  - [CVPR](#cvpr-2021)
  - [ICCV](#iccv-2021)
  - [AAAI](#aaai-2021)

- [2020](#2020)
  - [NeurIPS](#neurips-2020)
  - [CVPR](#cvpr-2020)
  - [AAAI](#aaai-2020)

- [2019](#2019)
  - [NeurIPS](#neurips-2019)
  - [CVPR](#cvpr-2019)
  - [ICCV](#iccv-2019)

- [2018](#2018)
  - [NeurIPS](#neurips-2018)
  - [CVPR](#cvpr-2018)
  - [AAAI](#aaai-2018)



# 2024


## CVPR-2024


- TIGER: Time-Varying Denoising Model for 3D Point Cloud Generation with Diffusion Process [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Ren_TIGER_Time-Varying_Denoising_Model_for_3D_Point_Cloud_Generation_with_CVPR_2024_paper.html)] [[paper with code](https://paperswithcode.com/paper/tiger-time-varying-denoising-model-for-3d)]

- Learning Continuous 3D Words for Text-to-Image Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Learning_Continuous_3D_Words_for_Text-to-Image_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2402.08654)] [[paper with code](https://paperswithcode.com/paper/learning-continuous-3d-words-for-text-to)]

- HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.17061)] [[paper with code](https://paperswithcode.com/paper/humangaussian-text-driven-3d-human-generation)]

- Interactive3D: Create What You Want by Interactive 3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Interactive3D_Create_What_You_Want_by_Interactive_3D_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2404.16510)] [[paper with code](https://paperswithcode.com/paper/interactive3d-create-what-you-want-by)]

- BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_BerfScene_Bev-conditioned_Equivariant_Radiance_Fields_for_Infinite_3D_Scene_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.02136)] [[paper with code](https://paperswithcode.com/paper/berfscene-bev-conditioned-equivariant)]

- DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Ju_DiffInDScene_Diffusion-based_High-Quality_3D_Indoor_Scene_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2306.00519)] [[paper with code](https://paperswithcode.com/paper/diffroom-diffusion-based-high-quality-3d-room)] [[code](https://github.com/akirahero/diffindscene)]

- Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cha_Text2HOI_Text-guided_3D_Motion_Generation_for_Hand-Object_Interaction_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2404.00562)] [[paper with code](https://paperswithcode.com/paper/text2hoi-text-guided-3d-motion-generation-for)] [[code](https://github.com/junukcha/text2hoi)]

- Design2Cloth: 3D Cloth Generation from 2D Masks [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Design2Cloth_3D_Cloth_Generation_from_2D_Masks_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2404.02686)] [[paper with code](https://paperswithcode.com/paper/design2cloth-3d-cloth-generation-from-2d)]

- ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Hollein_ViewDiff_3D-Consistent_Image_Generation_with_Text-to-Image_Models_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2403.01807)] [[paper with code](https://paperswithcode.com/paper/viewdiff-3d-consistent-image-generation-with)] [[code](https://github.com/facebookresearch/viewdiff)]

- CAD: Photorealistic 3D Generation via Adversarial Distillation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wan_CAD_Photorealistic_3D_Generation_via_Adversarial_Distillation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.06663)] [[paper with code](https://paperswithcode.com/paper/cad-photorealistic-3d-generation-via)]

- AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute Decomposition and Indexing [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_AttriHuman-3D_Editable_3D_Human_Avatar_Generation_with_Attribute_Decomposition_and_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.02209)] [[paper with code](https://paperswithcode.com/paper/attrihuman-3d-editable-3d-human-avatar)]

- 3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_3D-SceneDreamer_Text-Driven_3D-Consistent_Scene_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2403.09439)] [[paper with code](https://paperswithcode.com/paper/3d-scenedreamer-text-driven-3d-consistent)]

- Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Sherpa3D_Boosting_High-Fidelity_Text-to-3D_Generation_via_Coarse_3D_Prior_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.06655)] [[paper with code](https://paperswithcode.com/paper/sherpa3d-boosting-high-fidelity-text-to-3d)] [[code](https://github.com/liuff19/Sherpa3D)]

- DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DreamPropeller_Supercharge_Text-to-3D_Generation_with_Parallel_Sampling_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.17082)] [[paper with code](https://paperswithcode.com/paper/dreampropeller-supercharge-text-to-3d)] [[code](https://github.com/alexzhou907/dreampropeller)]

- One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_One-2-3-45_Fast_Single_Image_to_3D_Objects_with_Consistent_Multi-View_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.07885)] [[paper with code](https://paperswithcode.com/paper/one-2-3-45-fast-single-image-to-3d-objects)]

- MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Hu_MVD-Fusion_Single-view_3D_via_Depth-consistent_Multi-view_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2404.03656)] [[paper with code](https://paperswithcode.com/paper/mvd-fusion-single-view-3d-via-depth)]

- Holodeck: Language Guided Generation of 3D Embodied AI Environments [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Holodeck_Language_Guided_Generation_of_3D_Embodied_AI_Environments_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.09067)] [[paper with code](https://paperswithcode.com/paper/holodeck-language-guided-generation-of-3d)] [[code](https://github.com/allenai/Holodeck)]

- Joint2Human: High-Quality 3D Human Generation via Compact Spherical Embedding of 3D Joints [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Joint2Human_High-Quality_3D_Human_Generation_via_Compact_Spherical_Embedding_of_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.08591)] [[paper with code](https://paperswithcode.com/paper/joint2human-high-quality-3d-human-generation)]

- MPOD123: One Image to 3D Content Generation Using Mask-enhanced Progressive Outline-to-Detail Optimization [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xu_MPOD123_One_Image_to_3D_Content_Generation_Using_Mask-enhanced_Progressive_CVPR_2024_paper.html)] [[paper with code](https://paperswithcode.com/paper/mpod123-one-image-to-3d-content-generation)]

- Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Consistent3D_Towards_Consistent_High-Fidelity_Text-to-3D_Generation_with_Deterministic_Sampling_Prior_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2401.09050)] [[paper with code](https://paperswithcode.com/paper/consistent3d-towards-consistent-high-fidelity)] [[code](https://github.com/sail-sg/consistent3d)]

- DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_DiffSHEG_A_Diffusion-Based_Approach_for_Real-Time_Speech-driven_Holistic_3D_Expression_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2401.04747)] [[paper with code](https://paperswithcode.com/paper/diffsheg-a-diffusion-based-approach-for-real)]

- DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_DIRECT-3D_Learning_Direct_Text-to-3D_Generation_on_Massive_Noisy_3D_Data_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2406.04322)] [[paper with code](https://paperswithcode.com/paper/direct-3d-learning-direct-text-to-3d)] [[code](https://github.com/qihao067/direct3d)]

- Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Text-to-3D_Generation_with_Bidirectional_Diffusion_using_both_2D_and_3D_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.04963)] [[paper with code](https://paperswithcode.com/paper/text-to-3d-generation-with-bidirectional)]

- CLIP-Driven Open-Vocabulary 3D Scene Graph Generation via Cross-Modality Contrastive Learning [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_CLIP-Driven_Open-Vocabulary_3D_Scene_Graph_Generation_via_Cross-Modality_Contrastive_Learning_CVPR_2024_paper.html)] [[paper with code](https://paperswithcode.com/paper/clip-driven-open-vocabulary-3d-scene-graph)]

- DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaptation by Combining 3D GANs and Diffusion Priors [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Lei_DiffusionGAN3D_Boosting_Text-guided_3D_Generation_and_Domain_Adaptation_by_Combining_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.16837)] [[paper with code](https://paperswithcode.com/paper/diffusiongan3d-boosting-text-guided-3d)]

- Sculpt3D: Multi-View Consistent Text-to-3D Generation with Sparse 3D Prior [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Sculpt3D_Multi-View_Consistent_Text-to-3D_Generation_with_Sparse_3D_Prior_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2403.09140)] [[paper with code](https://paperswithcode.com/paper/sculpt3d-multi-view-consistent-text-to-3d)]

- PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_PI3D_Efficient_Text-to-3D_Generation_with_Pseudo-Image_Diffusion_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.09069)] [[paper with code](https://paperswithcode.com/paper/pi3d-efficient-text-to-3d-generation-with)]

- DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cao_DreamAvatar_Text-and-Shape_Guided_3D_Human_Avatar_Generation_via_Diffusion_Models_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2304.00916)] [[paper with code](https://paperswithcode.com/paper/dreamavatar-text-and-shape-guided-3d-human)] [[code](https://github.com/threestudio-project/threestudio)]

- GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yi_GaussianDreamer_Fast_Generation_from_Text_to_3D_Gaussians_by_Bridging_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2310.08529)] [[paper with code](https://paperswithcode.com/paper/gaussiandreamer-fast-generation-from-text-to)] [[code](https://github.com/hustvl/GaussianDreamer)]

- DreamComposer: Controllable 3D Object Generation via Multi-View Conditions [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_DreamComposer_Controllable_3D_Object_Generation_via_Multi-View_Conditions_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.03611)] [[paper with code](https://paperswithcode.com/paper/dreamcomposer-controllable-3d-object)]

- VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VP3D_Unleashing_2D_Visual_Prompt_for_Text-to-3D_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2403.17001)] [[paper with code](https://paperswithcode.com/paper/vp3d-unleashing-2d-visual-prompt-for-text-to)]

- GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_GPT-4Vision_is_a_Human-Aligned_Evaluator_for_Text-to-3D_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2401.04092)] [[paper with code](https://paperswithcode.com/paper/gpt-4v-ision-is-a-human-aligned-evaluator-for)] [[code](https://github.com/3DTopia/GPTEval3D)]

- Gaussian Shell Maps for Efficient 3D Human Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Abdal_Gaussian_Shell_Maps_for_Efficient_3D_Human_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.17857)] [[paper with code](https://paperswithcode.com/paper/gaussian-shell-maps-for-efficient-3d-human)]

- HumanRef: Single Image to 3D Human Generation via Reference-Guided Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HumanRef_Single_Image_to_3D_Human_Generation_via_Reference-Guided_Diffusion_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.16961)] [[paper with code](https://paperswithcode.com/paper/humanref-single-image-to-3d-human-generation)]

- POPDG: Popular 3D Dance Generation with PopDanceSet [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Luo_POPDG_Popular_3D_Dance_Generation_with_PopDanceSet_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2405.03178)] [[paper with code](https://paperswithcode.com/paper/popdg-popular-3d-dance-generation-with)] [[code](https://github.com/luke-luo1/popdg)]

- ControlRoom3D: Room Generation using Semantic Proxy Rooms [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Schult_ControlRoom3D_Room_Generation_using_Semantic_Proxy_Rooms_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.05208)] [[paper with code](https://paperswithcode.com/paper/controlroom3d-room-generation-using-semantic)]

- HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Huang_HumanNorm_Learning_Normal_Diffusion_Model_for_High-quality_and_Realistic_3D_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2310.01406)] [[paper with code](https://paperswithcode.com/paper/humannorm-learning-normal-diffusion-model-for)]

- Taming Mode Collapse in Score Distillation for Text-to-3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Taming_Mode_Collapse_in_Score_Distillation_for_Text-to-3D_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2401.00909)] [[paper with code](https://paperswithcode.com/paper/taming-mode-collapse-in-score-distillation)]

- Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Direct2.5_Diverse_Text-to-3D_Generation_via_Multi-view_2.5D_Diffusion_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.15980)] [[paper with code](https://paperswithcode.com/paper/direct2-5-diverse-text-to-3d-generation-via)]

- Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Schroppel_Neural_Point_Cloud_Diffusion_for_Disentangled_3D_Shape_and_Appearance_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.14124)] [[paper with code](https://paperswithcode.com/paper/neural-point-cloud-diffusion-for-disentangled)] [[code](https://github.com/lmb-freiburg/neural-point-cloud-diffusion)]

- GenZI: Zero-Shot 3D Human-Scene Interaction Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Li_GenZI_Zero-Shot_3D_Human-Scene_Interaction_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.17737)] [[paper with code](https://paperswithcode.com/paper/genzi-zero-shot-3d-human-scene-interaction)]

- CG-HOI: Contact-Guided 3D Human-Object Interaction Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Diller_CG-HOI_Contact-Guided_3D_Human-Object_Interaction_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.16097)] [[paper with code](https://paperswithcode.com/paper/cg-hoi-contact-guided-3d-human-object)]

- Rapid 3D Model Generation with Intuitive 3D Input [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Rapid_3D_Model_Generation_with_Intuitive_3D_Input_CVPR_2024_paper.html)] [[paper with code](https://paperswithcode.com/paper/rapid-3d-model-generation-with-intuitive-3d)]

- LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.11284)] [[paper with code](https://paperswithcode.com/paper/luciddreamer-towards-high-fidelity-text-to-3d)] [[code](https://github.com/envision-research/luciddreamer)]

- HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry for Enhanced 3D Text2Shape Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Leng_HyperSDFusion_Bridging_Hierarchical_Structures_in_Language_and_Geometry_for_Enhanced_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2403.00372)] [[paper with code](https://paperswithcode.com/paper/hypersdfusion-bridging-hierarchical)]

- Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2401.10786)] [[paper with code](https://paperswithcode.com/paper/sat2scene-3d-urban-scene-generation-from)]

- Text-Guided 3D Face Synthesis - From Generation to Editing [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Text-Guided_3D_Face_Synthesis_-_From_Generation_to_Editing_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.00375)] [[paper with code](https://paperswithcode.com/paper/text-guided-3d-face-synthesis-from-generation-1)]

- MAS: Multi-view Ancestral Sampling for 3D Motion Generation Using 2D Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Kapon_MAS_Multi-view_Ancestral_Sampling_for_3D_Motion_Generation_Using_2D_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2310.14729)] [[paper with code](https://paperswithcode.com/paper/mas-multi-view-ancestral-sampling-for-3d)]

- Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech Gesture Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Qi_Weakly-Supervised_Emotion_Transition_Learning_for_Diverse_3D_Co-speech_Gesture_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2311.17532)] [[paper with code](https://paperswithcode.com/paper/weakly-supervised-emotion-transition-learning)]

- DreamControl: Control-Based Text-to-3D Generation with 3D Self-Prior [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Huang_DreamControl_Control-Based_Text-to-3D_Generation_with_3D_Self-Prior_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2312.06439)] [[paper with code](https://paperswithcode.com/paper/dreamcontrol-control-based-text-to-3d)] [[code](https://github.com/tyhuang0428/dreamcontrol)]

- Diffusion Time-step Curriculum for One Image to 3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Diffusion_Time-step_Curriculum_for_One_Image_to_3D_Generation_CVPR_2024_paper.html)] [[arxiv](https://arxiv.org/abs/2404.04562)] [[paper with code](https://paperswithcode.com/paper/diffusion-time-step-curriculum-for-one-image)] [[code](https://github.com/yxymessi/dtc123)]


## ICLR-2024


- MagicDrive: Street View Generation with Diverse 3D Geometry Control [[paper](https://iclr.cc/virtual/2024/poster/17661)] [[arxiv](https://arxiv.org/abs/2310.02601)] [[paper with code](https://paperswithcode.com/paper/magicdrive-street-view-generation-with)] [[openreview](https://openreview.net/forum?id=sBQwvucduK)]

- Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation [[paper](https://iclr.cc/virtual/2024/poster/17951)] [[arxiv](https://arxiv.org/abs/2309.17296)] [[paper with code](https://paperswithcode.com/paper/navigating-the-design-space-of-equivariant)] [[openreview](https://openreview.net/forum?id=kzGuiRXZrQ)]

- Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping [[paper](https://iclr.cc/virtual/2024/poster/17566)] [[arxiv](https://arxiv.org/abs/2310.12474)] [[paper with code](https://paperswithcode.com/paper/enhancing-high-resolution-3d-generation)] [[code](https://github.com/fudan-zvg/pgc-3d)] [[openreview](https://openreview.net/forum?id=ukidfml68f)]

- TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields [[paper](https://iclr.cc/virtual/2024/poster/18478)] [[arxiv](https://arxiv.org/abs/2309.17175)] [[paper with code](https://paperswithcode.com/paper/textfield3d-towards-enhancing-open-vocabulary)] [[openreview](https://openreview.net/forum?id=WOiOzHG2zD)]

- Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation [[paper](https://iclr.cc/virtual/2024/poster/18523)] [[arxiv](https://arxiv.org/abs/2303.07937)] [[paper with code](https://paperswithcode.com/paper/let-2d-diffusion-model-know-3d-consistency)] [[code](https://github.com/KU-CVLAB/3DFuse)] [[openreview](https://openreview.net/forum?id=UbxWjq0UO2)]

- Training-free Multi-objective Diffusion Model for 3D Molecule Generation [[paper](https://iclr.cc/virtual/2024/poster/18459)] [[openreview](https://openreview.net/forum?id=X41c4uB4k0)]

- MVDream: Multi-view Diffusion for 3D Generation [[paper](https://iclr.cc/virtual/2024/poster/19063)] [[arxiv](https://arxiv.org/abs/2308.16512)] [[paper with code](https://paperswithcode.com/paper/mvdream-multi-view-diffusion-for-3d)] [[code](https://github.com/bytedance/mvdream)]

- DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation [[paper](https://iclr.cc/virtual/2024/poster/19581)] [[arxiv](https://arxiv.org/abs/2306.12422)] [[paper with code](https://paperswithcode.com/paper/dreamtime-an-improved-optimization-strategy)] [[openreview](https://openreview.net/forum?id=1bAUywYJTU)]

- Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors [[paper](https://iclr.cc/virtual/2024/poster/19607)] [[arxiv](https://arxiv.org/abs/2306.17843)] [[paper with code](https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object)] [[code](https://github.com/guochengqian/magic123)] [[openreview](https://openreview.net/forum?id=0jHkUDyEO9)]

- Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for 3D Molecule Generation [[paper](https://iclr.cc/virtual/2024/poster/18833)] [[openreview](https://openreview.net/forum?id=MIEnYtlGyv)]

- HIFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance [[paper](https://iclr.cc/virtual/2024/poster/18961)] [[arxiv](https://arxiv.org/abs/2305.18766)] [[paper with code](https://paperswithcode.com/paper/hifa-high-fidelity-text-to-3d-with-advanced)] [[code](https://github.com/JunzheJosephZhu/HiFA)] [[openreview](https://openreview.net/forum?id=IZMPWmcS3H)]

- Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model [[paper](https://iclr.cc/virtual/2024/poster/19538)] [[arxiv](https://arxiv.org/abs/2311.06214)] [[paper with code](https://paperswithcode.com/paper/instant3d-fast-text-to-3d-with-sparse-view)] [[openreview](https://openreview.net/forum?id=2lDQLiH1W4)]

- DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior [[paper](https://iclr.cc/virtual/2024/poster/19148)] [[arxiv](https://arxiv.org/abs/2310.16818)] [[paper with code](https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with)] [[code](https://github.com/deepseek-ai/dreamcraft3d)] [[openreview](https://openreview.net/forum?id=DDX1u29Gqr)]

- DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow [[paper](https://iclr.cc/virtual/2024/poster/19028)] [[arxiv](https://arxiv.org/abs/2403.14966)] [[paper with code](https://paperswithcode.com/paper/dreamflow-high-quality-text-to-3d-generation)] [[openreview](https://openreview.net/forum?id=GURqUuTebY)]


## AAAI-2024


- Explore 3D Dance Generation via Reward Model from Automatically-Ranked Demonstrations [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27783)] [[arxiv](https://arxiv.org/abs/2312.11442)] [[paper with code](https://paperswithcode.com/paper/explore-3d-dance-generation-via-reward-model)]

- Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27787)] [[arxiv](https://arxiv.org/abs/2401.02683)] [[paper with code](https://paperswithcode.com/paper/geometric-facilitated-denoising-diffusion)] [[code](https://github.com/LEOXC1571/GFMDiff)]

- Real3D: The Curious Case of Neural Scene Degeneration [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27863)]

- IT3D: Improved Text-to-3D Generation with Explicit View Synthesis [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27886)] [[arxiv](https://arxiv.org/abs/2308.11473)] [[paper with code](https://paperswithcode.com/paper/it3d-improved-text-to-3d-generation-with)] [[code](https://github.com/buaacyw/it3d-text-to-3d)]

- ContactGen: Contact-Guided Interactive 3D Human Generation for Partners [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27962)] [[arxiv](https://arxiv.org/abs/2401.17212)] [[paper with code](https://paperswithcode.com/paper/contactgen-contact-guided-interactive-3d)]

- SGFormer: Semantic Graph Transformer for Point Cloud-Based 3D Scene Graph Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28197)] [[arxiv](https://arxiv.org/abs/2303.11048)] [[paper with code](https://paperswithcode.com/paper/revisiting-transformer-for-point-cloud-based)]

- Controllable 3D Face Generation with Conditional Style Code Diffusion [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28283)] [[arxiv](https://arxiv.org/abs/2312.13941)] [[paper with code](https://paperswithcode.com/paper/controllable-3d-face-generation-with)] [[code](https://github.com/sxl142/tex-face)]

- Diverse and Stable 2D Diffusion Guided Text to 3D Generation with Noise Recalibration [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28476)]



# 2023


## NeurIPS-2023


- Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/01d64478381c33e29ed611f1719f5a37-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=hHUZ5V9XFu)]

- ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/0b68d474baf8dff30f3280c199a32089-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2311.05230)] [[paper with code](https://paperswithcode.com/paper/conrad-image-constrained-radiance-fields-for)] [[openreview](https://openreview.net/forum?id=roGYQvarnC)]

- ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1a87980b9853e84dfb295855b425c262-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2305.16213)] [[paper with code](https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse)] [[code](https://github.com/threestudio-project/threestudio)] [[openreview](https://openreview.net/forum?id=ppJuFSOAnM)]

- Debiasing Scores and Prompts of 2D Diffusion for View-consistent Text-to-3D Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/27725882a88f202e07319abbb3be7693-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2303.15413)] [[paper with code](https://paperswithcode.com/paper/debiasing-scores-and-prompts-of-2d-diffusion)] [[code](https://github.com/threestudio-project/threestudio)] [[openreview](https://openreview.net/forum?id=jgIrJeHHlz)]

- PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2c575c088de5cfef858b8837251f3027-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2312.04559)] [[paper with code](https://paperswithcode.com/paper/primdiffusion-volumetric-primitives-diffusion-1)] [[code](https://github.com/frozenburning/primdiffusion)] [[openreview](https://openreview.net/forum?id=ESCafo3oD5)]

- VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/54d2d38a56a74387d5916ee40e462295-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2307.16605)] [[paper with code](https://paperswithcode.com/paper/vpp-efficient-conditional-3d-generation-via)] [[code](https://github.com/qizekun/vpp)] [[openreview](https://openreview.net/forum?id=etd0ebzGOG)]

- XAGen: 3D Expressive Human Avatars Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/6d6f9908ea35313dd7566f5ce8c6e815-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2311.13574)] [[paper with code](https://paperswithcode.com/paper/xagen-3d-expressive-human-avatars-generation)] [[openreview](https://openreview.net/forum?id=eUf0CaS5AP)]

- Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/73af055566f5514b9863315133b84eda-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=1recIOnzOF)]

- DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d6c01b025cad37d5c8bab4ba18846c02-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2307.01831)] [[paper with code](https://paperswithcode.com/paper/dit-3d-exploring-plain-diffusion-transformers-1)] [[code](https://github.com/DiT-3D/DiT-3D)] [[openreview](https://openreview.net/forum?id=Se71ks7Mfz)]

- 3D molecule generation by denoising voxel grids [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/da1131a86ac3c70e0b7cae89c3d4df22-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.07473)] [[paper with code](https://paperswithcode.com/paper/3d-molecule-generation-by-denoising-voxel)] [[code](https://github.com/genentech/voxmol)] [[openreview](https://openreview.net/forum?id=Zyzluw0hC4)]

- Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ea1a7f7bc0fc14142106a84c94c826d0-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.17115)] [[paper with code](https://paperswithcode.com/paper/michelangelo-conditional-3d-shape-generation-1)] [[code](https://github.com/neuralcarver/michelangelo)] [[openreview](https://openreview.net/forum?id=xmxgMij3LY)]


## CVPR-2023


- Patch-Based 3D Natural Scene Generation From a Single Example [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Patch-Based_3D_Natural_Scene_Generation_From_a_Single_Example_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.12670)] [[paper with code](https://paperswithcode.com/paper/patch-based-3d-natural-scene-generation-from)]

- SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Cheng_SDFusion_Multimodal_3D_Shape_Completion_Reconstruction_and_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.04493)] [[paper with code](https://paperswithcode.com/paper/sdfusion-multimodal-3d-shape-completion)] [[code](https://github.com/yccyenchicheng/SDFusion)]

- 3D Neural Field Generation Using Triplane Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Shue_3D_Neural_Field_Generation_Using_Triplane_Diffusion_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.16677)] [[paper with code](https://paperswithcode.com/paper/3d-neural-field-generation-using-triplane)]

- High-Fidelity 3D Face Generation From Natural Language Descriptions [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_High-Fidelity_3D_Face_Generation_From_Natural_Language_Descriptions_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.03302)] [[paper with code](https://paperswithcode.com/paper/high-fidelity-3d-face-generation-from-natural)] [[code](https://github.com/zhuhao-nju/describe3d)]

- Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Score_Jacobian_Chaining_Lifting_Pretrained_2D_Diffusion_Models_for_3D_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.00774)] [[paper with code](https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d)] [[code](https://github.com/pals-ttic/sjc)]

- OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_OmniObject3D_Large-Vocabulary_3D_Object_Dataset_for_Realistic_Perception_Reconstruction_and_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2301.07525)] [[paper with code](https://paperswithcode.com/paper/omniobject3d-large-vocabulary-3d-object)] [[code](https://github.com/omniobject3d/omniobject3d)]

- RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.09869)] [[paper with code](https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d)] [[code](https://github.com/anciukevicius/renderdiffusion)]

- Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Metzer_Latent-NeRF_for_Shape-Guided_Generation_of_3D_Shapes_and_Textures_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.07600)] [[paper with code](https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d)] [[code](https://github.com/eladrich/latent-nerf)]

- Diffusion-Based Signed Distance Fields for 3D Shape Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Shim_Diffusion-Based_Signed_Distance_Fields_for_3D_Shape_Generation_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/diffusion-based-signed-distance-fields-for-3d)]

- MIME: Human-Aware 3D Scene Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yi_MIME_Human-Aware_3D_Scene_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.04360)] [[paper with code](https://paperswithcode.com/paper/mime-human-aware-3d-scene-generation)]

- Diffusion-Based Generation, Optimization, and Planning in 3D Scenes [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Diffusion-Based_Generation_Optimization_and_Planning_in_3D_Scenes_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2301.06015)] [[paper with code](https://paperswithcode.com/paper/diffusion-based-generation-optimization-and)] [[code](https://github.com/scenediffuser/Scene-Diffuser)]

- TAPS3D: Text-Guided 3D Textured Shape Generation From Pseudo Supervision [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_TAPS3D_Text-Guided_3D_Textured_Shape_Generation_From_Pseudo_Supervision_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13273)] [[paper with code](https://paperswithcode.com/paper/taps3d-text-guided-3d-textured-shape)] [[code](https://github.com/plusmultiply/taps3d)]


## ICLR-2023


- 3D generation on ImageNet [[paper](https://iclr.cc/virtual/2023/poster/12156)] [[arxiv](https://arxiv.org/abs/2303.01416)] [[openreview](https://openreview.net/forum?id=U2WjB9xxZ9q)]

- EVA3D: Compositional 3D Human Generation from 2D Image Collections [[paper](https://iclr.cc/virtual/2023/poster/12147)] [[arxiv](https://arxiv.org/abs/2210.04888)] [[paper with code](https://paperswithcode.com/paper/eva3d-compositional-3d-human-generation-from)] [[code](https://github.com/hongfz16/EVA3D)] [[openreview](https://openreview.net/forum?id=g7U9jD_2CUr)]

- ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation [[paper](https://iclr.cc/virtual/2023/poster/12167)] [[arxiv](https://arxiv.org/abs/2209.04145)] [[paper with code](https://paperswithcode.com/paper/iss-image-as-stetting-stone-for-text-guided)] [[code](https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation)] [[openreview](https://openreview.net/forum?id=GMRodZ8OlVr)]

- Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design [[paper](https://iclr.cc/virtual/2023/poster/11314)] [[arxiv](https://arxiv.org/abs/2210.04893)] [[paper with code](https://paperswithcode.com/paper/equivariant-shape-conditioned-generation-of)] [[code](https://github.com/keiradams/squid)] [[openreview](https://openreview.net/forum?id=4MbGnp4iPQ)]

- 3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction [[paper](https://iclr.cc/virtual/2023/poster/11022)] [[arxiv](https://arxiv.org/abs/2303.03543)] [[paper with code](https://paperswithcode.com/paper/3d-equivariant-diffusion-for-target-aware)] [[code](https://github.com/guanjq/targetdiff)] [[openreview](https://openreview.net/forum?id=kJqXEPXMsE0)]

- PV3D: A 3D Generative Model for Portrait Video Generation [[paper](https://iclr.cc/virtual/2023/poster/11700)] [[arxiv](https://arxiv.org/abs/2212.06384)] [[paper with code](https://paperswithcode.com/paper/pv3d-a-3d-generative-model-for-portrait-video)] [[openreview](https://openreview.net/forum?id=o3yygm3lnzS)]


## ICCV-2023


- Texture Generation on 3D Meshes with Point-UV Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.10490)] [[paper with code](https://paperswithcode.com/paper/texture-generation-on-3d-meshes-with-point-uv)]

- Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.09662)] [[paper with code](https://paperswithcode.com/paper/make-an-animation-large-scale-text)]

- CC3D: Layout-Conditioned Generation of Compositional 3D Scenes [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.12074)] [[paper with code](https://paperswithcode.com/paper/cc3d-layout-conditioned-generation-of)]

- DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.01921)] [[paper with code](https://paperswithcode.com/paper/difffacto-controllable-part-based-3d-point)]

- 3D-aware Image Generation using 2D Diffusion Models [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.17905)] [[paper with code](https://paperswithcode.com/paper/3d-aware-image-generation-using-2d-diffusion)]

- PG-RCNN: Semantic Surface Point Generation for 3D Object Detection [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2307.12637)] [[paper with code](https://paperswithcode.com/paper/pg-rcnn-semantic-surface-point-generation-for)] [[code](https://github.com/quotation2520/pg-rcnn)]

- Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.06714)] [[paper with code](https://paperswithcode.com/paper/single-stage-diffusion-nerf-a-unified)] [[code](https://github.com/Lakonik/SSDNeRF)]

- 3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.07378)] [[paper with code](https://paperswithcode.com/paper/3dhumangan-towards-photo-realistic-3d-aware)] [[code](https://github.com/3dhumangan/3dhumangan)]

- 3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.07546)] [[paper with code](https://paperswithcode.com/paper/3dhacker-spectrum-based-decision-boundary)]

- DreamBooth3D: Subject-Driven Text-to-3D Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13508)] [[paper with code](https://paperswithcode.com/paper/dreambooth3d-subject-driven-text-to-3d)]

- ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2203.07706)] [[paper with code](https://paperswithcode.com/paper/actformer-a-gan-transformer-framework-towards)]

- SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.12236)] [[paper with code](https://paperswithcode.com/paper/salad-part-level-latent-diffusion-for-3d)]

- HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.11261)] [[paper with code](https://paperswithcode.com/paper/hmd-nemo-online-3d-avatar-motion-generation)]

- Generative Multiplane Neural Radiance for 3D-Aware Image Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.01172)] [[paper with code](https://paperswithcode.com/paper/generative-multiplane-neural-radiance-for-3d)] [[code](https://github.com/virobo-15/gmnr)]

- FineDance: A Fine-grained Choreography Dataset for 3D Full Body Dance Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.03741)] [[paper with code](https://paperswithcode.com/paper/magic-multi-art-genre-intelligent)] [[code](https://github.com/li-ronghui/FineDance)]

- Learning Versatile 3D Shape Generation with Improved Auto-regressive Models [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-versatile-3d-shape-generation-with-1)]

- TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.02419)] [[paper with code](https://paperswithcode.com/paper/tm2d-bimodality-driven-3d-dance-generation)] [[code](https://github.com/Garfield-kh/TM2D)]

- ShapeScaffolder: Structure-Aware 3D Shape Generation from Text [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/shapescaffolder-structure-aware-3d-shape)]

- GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2206.07255)] [[paper with code](https://paperswithcode.com/paper/gram-hd-3d-consistent-image-generation-at)]

- SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.10417)] [[paper with code](https://paperswithcode.com/paper/sinc-spatial-composition-of-3d-human-motions)]

- Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation Using only Images [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.16758)] [[paper with code](https://paperswithcode.com/paper/towards-high-fidelity-text-guided-3d-face)]


## ICML-2023


- MolDiff: Addressing the Atom-Bond Inconsistency Problem in 3D Molecule Diffusion Generation [[paper](https://proceedings.mlr.press/v202/peng23b.html)] [[arxiv](https://arxiv.org/abs/2305.07508)] [[paper with code](https://paperswithcode.com/paper/moldiff-addressing-the-atom-bond)] [[code](https://github.com/pengxingang/moldiff)]

- Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D [[paper](https://proceedings.mlr.press/v202/qiang23a.html)] [[arxiv](https://arxiv.org/abs/2305.13266)] [[paper with code](https://paperswithcode.com/paper/coarse-to-fine-a-hierarchical-diffusion-model)] [[code](https://github.com/qiangbo1222/hierdiff)]

- Geometric Latent Diffusion Models for 3D Molecule Generation [[paper](https://proceedings.mlr.press/v202/xu23n.html)] [[arxiv](https://arxiv.org/abs/2305.01140)] [[paper with code](https://paperswithcode.com/paper/geometric-latent-diffusion-models-for-3d)] [[code](https://github.com/minkaixu/geoldm)]


## AAAI-2023


- 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25186)] [[arxiv](https://arxiv.org/abs/2212.01103)] [[paper with code](https://paperswithcode.com/paper/3d-togo-towards-text-guided-cross-category-3d)]

- Pose-Guided 3D Human Generation in Indoor Scene [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25195)]

- MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25206)] [[arxiv](https://arxiv.org/abs/2212.05897)] [[paper with code](https://paperswithcode.com/paper/multiact-long-term-3d-human-motion-generation)] [[code](https://github.com/TaeryungLee/MultiAct_RELEASE)]

- CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25214)]

- MDM: Molecular Diffusion Model for 3D Molecule Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25639)] [[arxiv](https://arxiv.org/abs/2209.05710)] [[paper with code](https://paperswithcode.com/paper/mdm-molecular-diffusion-model-for-3d-molecule)]



# 2022


## NeurIPS-2022


- ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3a33ae4d634b49b0866b4142a1f82a2f-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2207.09446)] [[paper with code](https://paperswithcode.com/paper/shapecrafter-a-recursive-text-conditioned-3d)] [[code](https://github.com/FreddieRao/ShapeCrafter)] [[openreview](https://openreview.net/forum?id=KUOKpojFr_)]

- LION: Latent Point Diffusion Models for 3D Shape Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/40e56dabe12095a5fc44a6e4c3835948-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.06978)] [[paper with code](https://paperswithcode.com/paper/lion-latent-point-diffusion-models-for-3d)] [[code](https://github.com/nv-tlabs/LION)] [[openreview](https://openreview.net/forum?id=tHK5ntjp-5K)]

- HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6030db5195150ac86d942186f4abdad8-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.09729)] [[paper with code](https://paperswithcode.com/paper/humanise-language-conditioned-human-motion)] [[code](https://github.com/Silverster98/HUMANISE)] [[openreview](https://openreview.net/forum?id=bntkx18xEb4)]

- SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/8ae9cf363ea625161f885b798c1f1f78-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=17KCLTbRymw)]

- GAUDI: A Neural Architect for Immersive 3D Scene Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/a03037317560b8c5f2fb4b6466d4c439-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2207.13751)] [[paper with code](https://paperswithcode.com/paper/gaudi-a-neural-architect-for-immersive-3d)] [[code](https://github.com/apple/ml-gaudi)] [[openreview](https://openreview.net/forum?id=xijYyYFlRIf)]

- AniFaceGAN: Animatable 3D-Aware Face Image Generation for Video Avatars [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/eae78bf2712f222f101bd7d12f875a57-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.06465)] [[paper with code](https://paperswithcode.com/paper/anifacegan-animatable-3d-aware-face-image)] [[code](https://github.com/YueWuHKUST/AniFaceGAN)] [[openreview](https://openreview.net/forum?id=LfHwpvDPGpx)]


## CVPR-2022


- Neural Template: Topology-Aware Reconstruction and Disentangled Generation of 3D Meshes [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.04942)] [[paper with code](https://paperswithcode.com/paper/neural-template-topology-aware-reconstruction-1)] [[code](https://github.com/edward1997104/Neural-Template)]

- AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.09516)] [[paper with code](https://paperswithcode.com/paper/autosdf-shape-priors-for-3d-completion)] [[code](https://github.com/yccyenchicheng/AutoSDF)]

- Towards Implicit Text-Guided 3D Shape Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.14622)] [[paper with code](https://paperswithcode.com/paper/towards-implicit-text-guided-3d-shape)] [[code](https://github.com/liuzhengzhe/towards-implicit-text-guided-shape-generation)]

- StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.11427)] [[paper with code](https://paperswithcode.com/paper/stylesdf-high-resolution-3d-consistent-image)] [[code](https://github.com/royorel/StyleSDF)]

- Bailando: 3D Dance Generation by Actor-Critic GPT With Choreographic Memory [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.13055)] [[paper with code](https://paperswithcode.com/paper/bailando-3d-dance-generation-by-actor-critic)] [[code](https://github.com/lisiyao21/bailando)]

- Sparse to Dense Dynamic 3D Facial Expression Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2105.07463)] [[paper with code](https://paperswithcode.com/paper/3d-to-4d-facial-expressions-generation-guided)]

- WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.12917)] [[paper with code](https://paperswithcode.com/paper/warpinggan-warping-multiple-uniform-priors)] [[code](https://github.com/yztang4/warpinggan)]

- GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.08867)] [[paper with code](https://paperswithcode.com/paper/gram-generative-radiance-manifolds-for-3d)]

- FLAG: Flow-Based 3D Avatar Generation From Sparse Observations [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.05789)] [[paper with code](https://paperswithcode.com/paper/flag-flow-based-3d-avatar-generation-from)]

- AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.11593)] [[paper with code](https://paperswithcode.com/paper/adaptpose-cross-dataset-adaptation-for-3d)] [[code](https://github.com/mgholamikn/AdaptPose)]


## ICLR-2022


- An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch [[paper](https://iclr.cc/virtual/2022/poster/7066)] [[paper with code](https://paperswithcode.com/paper/an-autoregressive-flow-model-for-3d-molecular)] [[openreview](https://openreview.net/forum?id=C03Ajc-NS5W)]


## ECCV-2022


- Autoregressive 3D Shape Generation via Canonical Mapping [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/2586_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2204.01955)] [[paper with code](https://paperswithcode.com/paper/autoregressive-3d-shape-generation-via)] [[code](https://github.com/AnjieCheng/CanonicalVAE)]

- Cross-Modal 3D Shape Generation and Manipulation [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4596_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.11795)] [[paper with code](https://paperswithcode.com/paper/cross-modal-3d-shape-generation-and)]

- PoseGPT: Quantization-Based 3D Human Motion Generation and Forecasting [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6693_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2210.10542)] [[paper with code](https://paperswithcode.com/paper/posegpt-quantization-based-3d-human-motion)] [[code](https://github.com/naver/posegpt)]

- TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/650_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.01696)] [[paper with code](https://paperswithcode.com/paper/tm2t-stochastic-and-tokenized-modeling-for)] [[code](https://github.com/EricGuo5513/TM2T)]


## ICML-2022


- Equivariant Diffusion for Molecule Generation in 3D [[paper](https://proceedings.mlr.press/v162/hoogeboom22a.html)] [[arxiv](https://arxiv.org/abs/2203.17003)] [[paper with code](https://paperswithcode.com/paper/equivariant-diffusion-for-molecule-generation)] [[code](https://github.com/ehoogeboom/e3_diffusion_for_molecules)]


## AAAI-2022


- DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20014)] [[arxiv](https://arxiv.org/abs/2103.10206)] [[paper with code](https://paperswithcode.com/paper/dancenet3d-music-based-dance-generation-with)] [[code](https://github.com/libuyu/phantomdancedataset)]

- EditVAE: Unsupervised Parts-Aware Controllable 3D Point Cloud Shape Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20027)] [[arxiv](https://arxiv.org/abs/2110.06679)]



# 2021


## NeurIPS-2021


- GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/725215ed82ab6306919b485b81ff9615-Abstract.html)] [[arxiv](https://arxiv.org/abs/2106.07802)] [[paper with code](https://paperswithcode.com/paper/geomol-torsional-geometric-generation-of)] [[code](https://github.com/PattanaikL/GeoMol)] [[openreview](https://openreview.net/forum?id=af_hng9tuNj)]


## CVPR-2021


- Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Generative_PointNet_Deep_Energy-Based_Learning_on_Unordered_Point_Sets_for_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2004.01301)] [[paper with code](https://paperswithcode.com/paper/generative-pointnet-energy-based-learning-on)] [[code](https://github.com/fei960922/GPointNet)]

- 3D Shape Generation With Grid-Based Implicit Functions [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Ibing_3D_Shape_Generation_With_Grid-Based_Implicit_Functions_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2107.10607)] [[paper with code](https://paperswithcode.com/paper/3d-shape-generation-with-grid-based-implicit-1)]

- Lifting 2D StyleGAN for 3D-Aware Face Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Lifting_2D_StyleGAN_for_3D-Aware_Face_Generation_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2011.13126)] [[paper with code](https://paperswithcode.com/paper/lifting-2d-stylegan-for-3d-aware-face)] [[code](https://github.com/seasonSH/LiftedGAN)]

- Diffusion Probabilistic Models for 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Diffusion_Probabilistic_Models_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.01458)] [[paper with code](https://paperswithcode.com/paper/diffusion-probabilistic-models-for-3d-point)] [[code](https://github.com/luost26/diffusion-point-cloud)]

- Learning Progressive Point Embeddings for 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Learning_Progressive_Point_Embeddings_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-progressive-point-embeddings-for-3d)]


## ICCV-2021


- AI Choreographer: Music Conditioned 3D Dance Generation With AIST++ [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Li_AI_Choreographer_Music_Conditioned_3D_Dance_Generation_With_AIST_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2101.08779)] [[paper with code](https://paperswithcode.com/paper/learn-to-dance-with-aist-music-conditioned-3d)] [[code](https://github.com/google-research/mint)]

- 3D Shape Generation and Completion Through Point-Voxel Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Zhou_3D_Shape_Generation_and_Completion_Through_Point-Voxel_Diffusion_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2104.03670)] [[paper with code](https://paperswithcode.com/paper/3d-shape-generation-and-completion-through)] [[code](https://github.com/alexzhou907/pvd)]

- Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projections Matching [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.03746)] [[paper with code](https://paperswithcode.com/paper/unsupervised-learning-of-fine-structure-1)] [[code](https://github.com/chenchao15/2d_projection_matching)]

- Deep Hybrid Self-Prior for Full 3D Mesh Generation [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Wei_Deep_Hybrid_Self-Prior_for_Full_3D_Mesh_Generation_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.08017)] [[paper with code](https://paperswithcode.com/paper/deep-hybrid-self-prior-for-full-3d-mesh)]

- Graph-to-3D: End-to-End Generation and Manipulation of 3D Scenes Using Scene Graphs [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Dhamo_Graph-to-3D_End-to-End_Generation_and_Manipulation_of_3D_Scenes_Using_Scene_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.08841)] [[paper with code](https://paperswithcode.com/paper/graph-to-3d-end-to-end-generation-and)] [[code](https://github.com/he-dhamo/graphto3d)]

- SPG: Unsupervised Domain Adaptation for 3D Object Detection via Semantic Point Generation [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Xu_SPG_Unsupervised_Domain_Adaptation_for_3D_Object_Detection_via_Semantic_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.06709)] [[paper with code](https://paperswithcode.com/paper/spg-unsupervised-domain-adaptation-for-3d)]


## AAAI-2021


- Single View Point Cloud Generation via Unified 3D Prototype [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16303)]



# 2020


## NeurIPS-2020


- Convolutional Generation of Textured 3D Meshes [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/098d86c982354a96556bd861823ebfbd-Abstract.html)] [[arxiv](https://arxiv.org/abs/2006.07660)] [[paper with code](https://paperswithcode.com/paper/convolutional-generation-of-textured-3d)] [[code](https://github.com/dariopavllo/convmesh)]

- Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic Flows [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/1349b36b01e0e804a6c2909a6d0ec72a-Abstract.html)] [[arxiv](https://arxiv.org/abs/2007.10973)]

- Unsupervised object-centric video generation and decomposition in 3D [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/20125fd9b2d43e340a35fb0278da235d-Abstract.html)] [[arxiv](https://arxiv.org/abs/2007.06705)] [[paper with code](https://paperswithcode.com/paper/unsupervised-object-centric-video-generation)] [[code](https://github.com/pmh47/o3v)]


## CVPR-2020


- Disentangled and Controllable Face Image Generation via 3D Imitative-Contrastive Learning [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Deng_Disentangled_and_Controllable_Face_Image_Generation_via_3D_Imitative-Contrastive_Learning_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.11660)] [[paper with code](https://paperswithcode.com/paper/disentangled-and-controllable-face-image)] [[code](https://github.com/microsoft/DisentangledFaceGAN)]

- Leveraging 2D Data to Learn Textured 3D Mesh Generation [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Henderson_Leveraging_2D_Data_to_Learn_Textured_3D_Mesh_Generation_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.04180)] [[paper with code](https://paperswithcode.com/paper/leveraging-2d-data-to-learn-textured-3d-mesh)] [[code](https://github.com/pmh47/textured-mesh-gen)]


## AAAI-2020


- Rank3DGAN: Semantic Mesh Generation Using Relative Attributes [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6011)] [[arxiv](https://arxiv.org/abs/1905.10257)] [[paper with code](https://paperswithcode.com/paper/rank3dgan-semantic-mesh-generation-using)]



# 2019


## NeurIPS-2019


- Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/a4d8e2a7e0d0c102339f97716d2fdfb6-Abstract.html)] [[arxiv](https://arxiv.org/abs/1906.00957)] [[paper with code](https://paperswithcode.com/paper/symmetry-adapted-generation-of-3d-point-sets)] [[code](https://github.com/atomistic-machine-learning/G-SchNet)]

- Learning elementary structures for 3D shape generation and matching [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/d360a502598a4b64b936683b44a5523a-Abstract.html)] [[arxiv](https://arxiv.org/abs/1908.04725)] [[paper with code](https://paperswithcode.com/paper/learning-elementary-structures-for-3d-shape)] [[code](https://github.com/TheoDEPRELLE/AtlasNetV2)]


## CVPR-2019


- PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_PointRCNN_3D_Object_Proposal_Generation_and_Detection_From_Point_Cloud_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1812.04244)] [[paper with code](https://paperswithcode.com/paper/pointrcnn-3d-object-proposal-generation-and)] [[code](https://github.com/sshaoshuai/PointRCNN)]


## ICCV-2019


- Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Wen_Pixel2Mesh_Multi-View_3D_Mesh_Generation_via_Deformation_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1908.01491)] [[paper with code](https://paperswithcode.com/paper/pixel2mesh-multi-view-3d-mesh-generation-via)] [[code](https://github.com/walsvid/Pixel2MeshPlusPlus)]

- Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Sharma_Monocular_3D_Human_Pose_Estimation_by_Generation_and_Ordinal_Ranking_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.01324)] [[paper with code](https://paperswithcode.com/paper/monocular-3d-human-pose-estimation-by-1)] [[code](https://github.com/ssfootball04/generative_pose)]

- PointFlow: 3D Point Cloud Generation With Continuous Normalizing Flows [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Yang_PointFlow_3D_Point_Cloud_Generation_With_Continuous_Normalizing_Flows_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1906.12320)] [[paper with code](https://paperswithcode.com/paper/pointflow-3d-point-cloud-generation-with)] [[code](https://github.com/stevenygd/PointFlow)]

- Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape Representation Learning and Generation [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Bouritsas_Neural_3D_Morphable_Models_Spiral_Convolutional_Networks_for_3D_Shape_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1905.02876)] [[paper with code](https://paperswithcode.com/paper/neural-3d-morphable-models-spiral)] [[code](https://github.com/gbouritsas/Neural3DMM)]


# 2018


## NeurIPS-2018


- Visual Object Networks: Image Generation with Disentangled 3D Representations [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/92cc227532d17e56e07902b254dfad10-Abstract.html)] [[arxiv](https://arxiv.org/abs/1812.02725)] [[paper with code](https://paperswithcode.com/paper/visual-object-networks-image-generation-with-1)] [[code](https://github.com/junyanz/VON)]


## CVPR-2018


- A Papier-Mâché Approach to Learning 3D Surface Generation [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1802.05384)]


## AAAI-2018


- Learning Adversarial 3D Model Generation With 2D Image Enhancer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/12223)]

- Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/12278)] [[arxiv](https://arxiv.org/abs/1706.07036)] [[paper with code](https://paperswithcode.com/paper/learning-efficient-point-cloud-generation-for)] [[code](https://github.com/chenhsuanlin/3D-point-cloud-generation)]