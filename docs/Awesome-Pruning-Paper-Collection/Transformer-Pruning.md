# Awesome Transformer Pruning Paper Collection


- [2024](#2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICCV](#iccv-2023)
  - [ICML](#icml-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [ECCV](#eccv-2022)
  - [ICML](#icml-2022)
  - [AAAI](#aaai-2022)



# 2024


## ICLR-2024


- The Need for Speed: Pruning Transformers with One Recipe [[paper](https://iclr.cc/virtual/2024/poster/18819)] [[arxiv](https://arxiv.org/abs/2403.17921)] [[paper with code](https://paperswithcode.com/paper/the-need-for-speed-pruning-transformers-with)] [[code](https://github.com/skhaki18/optin-transformer-pruning)] [[openreview](https://openreview.net/forum?id=MVmT6uQ3cQ)]

- Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance [[paper](https://iclr.cc/virtual/2024/poster/19175)] [[openreview](https://openreview.net/forum?id=COO51g41Q4)]

- Data-independent Module-aware Pruning for Hierarchical Vision Transformers [[paper](https://iclr.cc/virtual/2024/poster/19362)] [[openreview](https://openreview.net/forum?id=7Ol6foUi1G)]


## AAAI-2024


- VSFormer: Visual-Spatial Fusion Transformer for Correspondence Pruning [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28123)] [[arxiv](https://arxiv.org/abs/2312.08774)] [[paper with code](https://paperswithcode.com/paper/vsformer-visual-spatial-fusion-transformer)] [[code](https://github.com/sugar-fly/vsformer)]

- UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29296)] [[arxiv](https://arxiv.org/abs/2401.06426)] [[paper with code](https://paperswithcode.com/paper/updp-a-unified-progressive-depth-pruner-for)]

- Fairness-Aware Structured Pruning in Transformers [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/30256)] [[arxiv](https://arxiv.org/abs/2312.15398)] [[paper with code](https://paperswithcode.com/paper/fairness-aware-structured-pruning-in)] [[code](https://github.com/chandar-lab/fasp)]



# 2023


## NeurIPS-2023


- Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/cdaac2a02c4fdcae77ba083b110efcc3-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2305.15805)] [[paper with code](https://paperswithcode.com/paper/dynamic-context-pruning-for-efficient-and)] [[openreview](https://openreview.net/forum?id=uvdJgFFzby)]


## CVPR-2023


- X-Pruner: eXplainable Pruning for Vision Transformers [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_X-Pruner_eXplainable_Pruning_for_Vision_Transformers_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.04935)] [[paper with code](https://paperswithcode.com/paper/x-pruner-explainable-pruning-for-vision)] [[code](https://github.com/vickyyu90/xpruner)]

- Global Vision Transformer Pruning With Hessian-Aware Saliency [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Global_Vision_Transformer_Pruning_With_Hessian-Aware_Saliency_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2110.04869)] [[paper with code](https://paperswithcode.com/paper/nvit-vision-transformer-compression-and-1)] [[code](https://github.com/NVlabs/NViT)]

- Joint Token Pruning and Squeezing Towards More Aggressive Compression of Vision Transformers [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Joint_Token_Pruning_and_Squeezing_Towards_More_Aggressive_Compression_of_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.10716)] [[paper with code](https://paperswithcode.com/paper/joint-token-pruning-and-squeezing-towards)] [[code](https://github.com/megvii-research/tps-cvpr2023)]


## ICCV-2023


- Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.01045)] [[paper with code](https://paperswithcode.com/paper/dynamic-token-pruning-in-plain-vision)] [[code](https://github.com/zbwxp/Dynamic-Token-Pruning)]


## ICML-2023


- UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers [[paper](https://proceedings.mlr.press/v202/shi23e.html)] [[arxiv](https://arxiv.org/abs/2301.13741)] [[paper with code](https://paperswithcode.com/paper/upop-unified-and-progressive-pruning-for)] [[code](https://github.com/sdc17/upop)]


## AAAI-2023


- GOHSP: A Unified Framework of Graph and Optimization-Based Heterogeneous Structured Pruning for Vision Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/26298)] [[arxiv](https://arxiv.org/abs/2301.05345)] [[paper with code](https://paperswithcode.com/paper/gohsp-a-unified-framework-of-graph-and)]



# 2022


## NeurIPS-2022


- SAViT: Structure-Aware Vision Transformer Pruning via Collaborative Optimization [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b11c5cc84b6da2838db348b37dbd1a2-Abstract-Conference.html)] [[paper with code](https://paperswithcode.com/paper/savit-structure-aware-vision-transformer)] [[code](https://github.com/hikvision-research/savit)] [[openreview](https://openreview.net/forum?id=w5DacXWzQ-Q)]

- A Fast Post-Training Pruning Framework for Transformers [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/987bed997ab668f91c822a09bce3ea12-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2204.09656)] [[paper with code](https://paperswithcode.com/paper/a-fast-post-training-pruning-framework-for)] [[code](https://github.com/WoosukKwon/retraining-free-pruning)] [[openreview](https://openreview.net/forum?id=0GRBKLBjJE)]


## ECCV-2022


- PPT: Token-Pruned Pose Transformer for Monocular and Multi-View Human Pose Estimation [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/46_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2209.08194)] [[paper with code](https://paperswithcode.com/paper/ppt-token-pruned-pose-transformer-for)] [[code](https://github.com/howiema/ppt)]

- SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6265_ECCV_2022_paper.php)]


## ICML-2022


- PLATON: Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance [[paper](https://proceedings.mlr.press/v162/zhang22ao.html)] [[arxiv](https://arxiv.org/abs/2206.12562)] [[paper with code](https://paperswithcode.com/paper/platon-pruning-large-transformer-models-with)] [[code](https://github.com/qingruzhang/platon)]


## AAAI-2022


- Width & Depth Pruning for Vision Transformers [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20222)]