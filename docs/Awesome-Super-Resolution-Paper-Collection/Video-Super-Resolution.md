# Awesome Video-Super-Resolution Paper Collection

- [2024](#2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [CVPR](#cvpr-2023)
  - [ICCV](#iccv-2023)
  - [IJCAI](#ijcai-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [CVPR](#cvpr-2022)
  - [ECCV](#eccv-2022)

- [2021](#2021)
  - [CVPR](#cvpr-2021)
  - [ICCV](#iccv-2021)
  - [AAAI](#aaai-2021)

- [2020](#2020)
  - [CVPR](#cvpr-2020)
  - [ECCV](#eccv-2020)
  - [AAAI](#aaai-2020)

- [2019](#2019)
  - [CVPR](#cvpr-2019)
  - [ICCV](#iccv-2019)
  - [AAAI](#aaai-2019)

- [2018](#2018)
  - [CVPR](#cvpr-2018)



# 2024


## AAAI-2024


- Arbitrary-Scale Video Super-resolution Guided by Dynamic Context [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28003)]

- SAVSR: Arbitrary-Scale Video Super-Resolution via a Learned Scale-Adaptive Network [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28114)]

- Semantic Lens: Instance-Centric Semantic Alignment for Video Super-resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28321)] [[arxiv](https://arxiv.org/abs/2312.07823)] [[paper with code](https://paperswithcode.com/paper/semantic-lens-instance-centric-semantic)] [[code](https://github.com/Tang1705/Semantic-Lens-AAAI24)]

- NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-world Video Super-Resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28942)] [[arxiv](https://arxiv.org/abs/2305.14669)] [[paper with code](https://paperswithcode.com/paper/negvsr-augmenting-negatives-for-generalized)]



# 2023


## CVPR-2023


- Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Towards_High-Quality_and_Efficient_Video_Super-Resolution_via_Spatial-Temporal_Data_Overfitting_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.08331)] [[paper with code](https://paperswithcode.com/paper/towards-high-quality-and-efficient-video)] [[code](https://github.com/coulsonlee/stdo-cvpr2023)]

- Compression-Aware Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/compression-aware-video-super-resolution)] [[code](https://github.com/aprblue/cavsr)]

- Structured Sparsity Learning for Efficient Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Xia_Structured_Sparsity_Learning_for_Efficient_Video_Super-Resolution_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2206.07687)] [[paper with code](https://paperswithcode.com/paper/residual-sparsity-connection-learning-for)] [[code](https://github.com/zj-binxia/ssl)]

- Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Learning_Spatial-Temporal_Implicit_Neural_Representations_for_Event-Guided_Video_Super-Resolution_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13767)] [[paper with code](https://paperswithcode.com/paper/learning-spatial-temporal-implicit-neural)] [[code](https://github.com/yunfanLu/INR-Event-VSR)]

- Consistent Direct Time-of-Flight Video Depth Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Consistent_Direct_Time-of-Flight_Video_Depth_Super-Resolution_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.08658)] [[paper with code](https://paperswithcode.com/paper/consistent-direct-time-of-flight-video-depth)] [[code](https://github.com/facebookresearch/dvsr)]


## ICCV-2023


- MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2307.07988)] [[paper with code](https://paperswithcode.com/paper/motif-learning-motion-trajectories-with-local)] [[code](https://github.com/sichun233746/motif)]

- Learning Data-Driven Vector-Quantized Degradation Model for Animation Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.09826)] [[paper with code](https://paperswithcode.com/paper/learning-data-driven-vector-quantized)] [[code](https://github.com/researchmm/vqd-sr)]

- Multi-Frequency Representation Enhancement with Privilege Information for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/multi-frequency-representation-enhancement)]


## IJCAI-2023


- DFVSR: Directional Frequency Video Super-Resolution via Asymmetric and Enhancement Alignment Network [[paper](https://www.ijcai.org/proceedings/2023/76)]


## AAAI-2023


- Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25165)]

- Accelerating the Training of Video Super-resolution Models [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25246)] [[arxiv](https://arxiv.org/abs/2205.05069)] [[paper with code](https://paperswithcode.com/paper/accelerating-the-training-of-video-super)]

- Mitigating Artifacts in Real-World Video Super-resolution Models [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25398)] [[arxiv](https://arxiv.org/abs/2212.07339)] [[paper with code](https://paperswithcode.com/paper/mitigating-artifacts-in-real-world-video)] [[code](https://github.com/tencentarc/fastrealvsr)]



# 2022


## NeurIPS-2022


- AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/48cca987b3af66e1a607abd4820b330d-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2206.07038)] [[paper with code](https://paperswithcode.com/paper/animesr-learning-real-world-super-resolution)] [[code](https://github.com/tencentarc/animesr)] [[openreview](https://openreview.net/forum?id=4kjQZTNz-NH)]

- Rethinking Alignment in Video Super-Resolution Transformers [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/ea4d65c59073e8faf79222654d25fbe2-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2207.08494)] [[paper with code](https://paperswithcode.com/paper/rethinking-alignment-in-video-super)] [[code](https://github.com/xpixelgroup/rethinkvsralignment)] [[openreview](https://openreview.net/forum?id=NgIf3FpcHie)]


## CVPR-2022


- Memory-Augmented Non-Local Attention for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2108.11048)] [[paper with code](https://paperswithcode.com/paper/memory-augmented-non-local-attention-for)] [[code](https://github.com/jiy173/MANA)]

- VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.04647)] [[paper with code](https://paperswithcode.com/paper/videoinr-learning-video-implicit-neural-1)] [[code](https://github.com/picsart-ai-research/videoinr-continuous-space-time-super-resolution)]

- Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2205.05264)] [[paper with code](https://paperswithcode.com/paper/spatial-temporal-space-hand-in-hand-spatial)]

- Stable Long-Term Recurrent Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.08950)] [[paper with code](https://paperswithcode.com/paper/stable-long-term-recurrent-video-super)] [[code](https://github.com/bjmch/MRVSR)]

- BasicVSR++: Improving Video Super-Resolution With Enhanced Propagation and Alignment [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2104.13371)] [[paper with code](https://paperswithcode.com/paper/basicvsr-improving-video-super-resolution)] [[code](https://github.com/open-mmlab/mmediting)]

- Look Back and Forth: Video Super-Resolution With Explicit Temporal Difference Modeling [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2204.07114)] [[paper with code](https://paperswithcode.com/paper/look-back-and-forth-video-super-resolution)] [[code](https://github.com/junpan19/ETDM)]

- RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.14186)] [[paper with code](https://paperswithcode.com/paper/rstt-real-time-spatial-temporal-transformer)] [[code](https://github.com/llmpass/RSTT)]

- Learning Trajectory-Aware Transformer for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2204.04216)] [[paper with code](https://paperswithcode.com/paper/learning-trajectory-aware-transformer-for)] [[code](https://github.com/researchmm/TTVSR)]

- Reference-Based Video Super-Resolution Using Multi-Camera Video Triplets [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.14537)] [[paper with code](https://paperswithcode.com/paper/reference-based-video-super-resolution-using)] [[code](https://github.com/codeslake/RefVSR)]

- Investigating Tradeoffs in Real-World Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2111.12704)] [[paper with code](https://paperswithcode.com/paper/investigating-tradeoffs-in-real-world-video)] [[code](https://github.com/ckkelvinchan/realbasicvsr)]


## ECCV-2022


- Real-RawVSR: Real-World Raw Video Super-Resolution with a Benchmark Dataset [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/1804_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2209.12475)] [[paper with code](https://paperswithcode.com/paper/real-rawvsr-real-world-raw-video-super)] [[code](https://github.com/zmzhang1998/Real-RawVSR)]

- A Codec Information Assisted Framework for Efficient Compressed Video Super-Resolution [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6420_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2210.08229)] [[paper with code](https://paperswithcode.com/paper/a-codec-information-assisted-framework-for)]

- Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/1814_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2208.03012)] [[paper with code](https://paperswithcode.com/paper/learning-spatiotemporal-frequency-transformer)] [[code](https://github.com/researchmm/ftvsr)]

- Towards Interpretable Video Super-Resolution via Alternating Optimization [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3116_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.10765)] [[paper with code](https://paperswithcode.com/paper/towards-interpretable-video-super-resolution)] [[code](https://github.com/caojiezhang/davsr)]


# 2021


## CVPR-2021


- BasicVSR: The Search for Essential Components in Video Super-Resolution and Beyond [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2012.02181)] [[paper with code](https://paperswithcode.com/paper/basicvsr-the-search-for-essential-components)] [[code](https://github.com/open-mmlab/mmediting/blob/master/configs/restorers/basicvsr/README.md)]

- Temporal Modulation Network for Controllable Space-Time Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Temporal_Modulation_Network_for_Controllable_Space-Time_Video_Super-Resolution_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2104.10642)] [[paper with code](https://paperswithcode.com/paper/temporal-modulation-network-for-controllable)] [[code](https://github.com/CS-GangXu/TMNet)]

- Space-Time Distillation for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Space-Time_Distillation_for_Video_Super-Resolution_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/space-time-distillation-for-video-super)]

- Turning Frequency to Resolution: Video Super-Resolution via Event Cameras [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Turning_Frequency_to_Resolution_Video_Super-Resolution_via_Event_Cameras_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/turning-frequency-to-resolution-video-super)]


## ICCV-2021


- Omniscient Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Yi_Omniscient_Video_Super-Resolution_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.15683)] [[paper with code](https://paperswithcode.com/paper/omniscient-video-super-resolution)]

- COMISR: Compression-Informed Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Li_COMISR_Compression-Informed_Video_Super-Resolution_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2105.01237)] [[paper with code](https://paperswithcode.com/paper/comisr-compression-informed-video-super)] [[code](https://github.com/google-research/google-research)]

- Deep Blind Video Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Pan_Deep_Blind_Video_Super-Resolution_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2003.04716)] [[paper with code](https://paperswithcode.com/paper/deep-blind-video-super-resolution)] [[code](https://github.com/csbhr/Deep-Blind-VSR)]

- Real-World Video Super-Resolution: A Benchmark Dataset and a Decomposition Based Learning Scheme [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Yang_Real-World_Video_Super-Resolution_A_Benchmark_Dataset_and_a_Decomposition_Based_ICCV_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/real-world-video-super-resolution-a-benchmark)] [[code](https://github.com/ianyeung/realvsr)]

- Efficient Video Compression via Content-Adaptive Super-Resolution [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Khani_Efficient_Video_Compression_via_Content-Adaptive_Super-Resolution_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2104.02322)] [[paper with code](https://paperswithcode.com/paper/efficient-video-compression-via-content)] [[code](https://github.com/AdaptiveVC/SRVC)]


## AAAI-2021


- Understanding Deformable Alignment in Video Super-Resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16181)] [[arxiv](https://arxiv.org/abs/2009.07265)] [[paper with code](https://paperswithcode.com/paper/understanding-deformable-alignment-in-video)]

- Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16310)] [[arxiv](https://arxiv.org/abs/2103.11744)] [[paper with code](https://paperswithcode.com/paper/large-motion-video-super-resolution-with-dual)]



# 2020


## CVPR-2020


- Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Xiang_Zooming_Slow-Mo_Fast_and_Accurate_One-Stage_Space-Time_Video_Super-Resolution_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2002.11616)] [[paper with code](https://paperswithcode.com/paper/zooming-slow-mo-fast-and-accurate-one-stage)] [[code](https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020)]

- TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1812.02898)] [[paper with code](https://paperswithcode.com/paper/tdan-temporally-deformable-alignment-network-1)] [[code](https://github.com/YapengTian/TDAN-VSR-CVPR-2020)]

- Video Super-Resolution With Temporal Group Attention [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Isobe_Video_Super-Resolution_With_Temporal_Group_Attention_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2007.10595)] [[paper with code](https://paperswithcode.com/paper/video-super-resolution-with-temporal-group-1)] [[code](https://github.com/junpan19/VSR_TGA)]


## ECCV-2020


- MuCAN: Multi-Correspondence Aggregation Network for Video Super-Resolution [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/1086_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2007.11803)]

- Video Super-Resolution with Recurrent Structure-Detail Network [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/1698_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2008.00455)]


## AAAI-2020


- JSI-GAN: GAN-Based Joint Super-Resolution and Inverse Tone-Mapping with Pixel-Wise Task-Specific Filters for UHD HDR Video [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6789)] [[arxiv](https://arxiv.org/abs/1909.04391)] [[paper with code](https://paperswithcode.com/paper/jsi-gan-gan-based-joint-super-resolution-and)] [[code](https://github.com/JihyongOh/JSI-GAN)]

- Video Face Super-Resolution with Motion-Adaptive Feedback Cell [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6934)] [[arxiv](https://arxiv.org/abs/2002.06378)] [[paper with code](https://paperswithcode.com/paper/video-face-super-resolution-with-motion)]



# 2019


## CVPR-2019


- Recurrent Back-Projection Network for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Haris_Recurrent_Back-Projection_Network_for_Video_Super-Resolution_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1903.10128)] [[paper with code](https://paperswithcode.com/paper/recurrent-back-projection-network-for-video)] [[code](https://github.com/alterzero/RBPN-PyTorch)]

- Fast Spatio-Temporal Residual Network for Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Fast_Spatio-Temporal_Residual_Network_for_Video_Super-Resolution_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.02870)] [[paper with code](https://paperswithcode.com/paper/fast-spatio-temporal-residual-network-for)]


## ICCV-2019


- Progressive Fusion Video Super-Resolution Network via Exploiting Non-Local Spatio-Temporal Correlations [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Yi_Progressive_Fusion_Video_Super-Resolution_Network_via_Exploiting_Non-Local_Spatio-Temporal_Correlations_ICCV_2019_paper.html)] [[paper with code](https://paperswithcode.com/paper/progressive-fusion-video-super-resolution)] [[code](https://github.com/psychopa4/PFNL)]

- Two-Stream Action Recognition-Oriented Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Zhang_Two-Stream_Action_Recognition-Oriented_Video_Super-Resolution_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1903.05577)] [[paper with code](https://paperswithcode.com/paper/two-stream-oriented-video-super-resolution)] [[code](https://github.com/AlanZhang1995/TwoStreamSR)]


## AAAI-2019


- Frame and Feature-Context Video Super-Resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4502)] [[arxiv](https://arxiv.org/abs/1909.13057)] [[paper with code](https://paperswithcode.com/paper/frame-and-feature-context-video-super)]

- Residual Invertible Spatio-Temporal Network for Video Super-Resolution [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4550)]



# 2018


## CVPR-2018


- Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.html)] [[paper with code](https://paperswithcode.com/paper/deep-video-super-resolution-network-using)] [[code](https://github.com/yhjo09/VSR-DUF)]

- Frame-Recurrent Video Super-Resolution [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Sajjadi_Frame-Recurrent_Video_Super-Resolution_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1801.04590)]