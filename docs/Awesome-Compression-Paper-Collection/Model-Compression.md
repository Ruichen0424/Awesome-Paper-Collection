# Awesome Model Compression Paper Collection

- [2024](#2024)
  - [ICLR](#iclr-2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICLR](#iclr-2023)
  - [ICCV](#iccv-2023)
  - [ICML](#icml-2023)
  - [ACL](#acl-2023)
  - [IJCAI](#ijcai-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [CVPR](#cvpr-2022)
  - [ICLR](#iclr-2022)
  - [ECCV](#eccv-2022)
  - [ICML](#icml-2022)
  - [ACL](#acl-2022)
  - [AAAI](#aaai-2022)

- [2021](#2021)
  - [NeurIPS](#neurips-2021)
  - [CVPR](#cvpr-2021)
  - [ICLR](#iclr-2021)
  - [ICCV](#iccv-2021)
  - [ACL](#acl-2021)
  - [AAAI](#aaai-2021)

- [2020](#2020)
  - [NeurIPS](#neurips-2020)
  - [CVPR](#cvpr-2020)
  - [ICLR](#iclr-2020)
  - [ECCV](#eccv-2020)
  - [ICML](#icml-2020)
  - [AAAI](#aaai-2020)

- [2019](#2019)
  - [NeurIPS](#neurips-2019)
  - [CVPR](#cvpr-2019)
  - [ICLR](#iclr-2019)
  - [ICCV](#iccv-2019)
  - [ICML](#icml-2019)
  - [IJCAI](#ijcai-2019)
  - [AAAI](#aaai-2019)

- [2018](#2018)
  - [NeurIPS](#neurips-2018)
  - [CVPR](#cvpr-2018)
  - [ICLR](#iclr-2018)
  - [ECCV](#eccv-2018)
  - [ICML](#icml-2018)
  - [ACL](#acl-2018)


# 2024


## ICLR-2024


- Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs [[paper](https://iclr.cc/virtual/2024/poster/17575)] [[arxiv](https://arxiv.org/abs/2310.01801)] [[paper with code](https://paperswithcode.com/paper/model-tells-you-what-to-discard-adaptive-kv)] [[openreview](https://openreview.net/forum?id=uNrFpDPMyo)]

- Compressed Context Memory for Online Language Model Interaction [[paper](https://iclr.cc/virtual/2024/poster/19404)] [[arxiv](https://arxiv.org/abs/2312.03414)] [[paper with code](https://paperswithcode.com/paper/compressed-context-memory-for-online-language)] [[code](https://github.com/snu-mllab/context-memory)] [[openreview](https://openreview.net/forum?id=64kSvC4iPg)]

- In-context Autoencoder for Context Compression in a Large Language Model [[paper](https://iclr.cc/virtual/2024/poster/17573)] [[arxiv](https://arxiv.org/abs/2307.06945)] [[paper with code](https://paperswithcode.com/paper/in-context-autoencoder-for-context)] [[code](https://github.com/getao/icae)] [[openreview](https://openreview.net/forum?id=uREj4ZuGJE)]

- Language Modeling Is Compression [[paper](https://iclr.cc/virtual/2024/poster/17997)] [[arxiv](https://arxiv.org/abs/2309.10668)] [[paper with code](https://paperswithcode.com/paper/language-modeling-is-compression)] [[code](https://github.com/google-deepmind/language_modeling_is_compression)] [[openreview](https://openreview.net/forum?id=jznbgiynus)]

- In defense of parameter sharing for model-compression [[paper](https://iclr.cc/virtual/2024/poster/17401)] [[arxiv](https://arxiv.org/abs/2310.11611)] [[paper with code](https://paperswithcode.com/paper/in-defense-of-parameter-sharing-for-model)] [[openreview](https://openreview.net/forum?id=ypAT2ixD4X)]


## AAAI-2024


- EPSD: Early Pruning with Self-Distillation for Efficient Model Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29004)] [[arxiv](https://arxiv.org/abs/2402.00084)] [[paper with code](https://paperswithcode.com/paper/epsd-early-pruning-with-self-distillation-for)]

- QCS-SGM+: Improved Quantized Compressed Sensing with Score-Based Generative Models [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29347)]



# 2023


## NeurIPS-2023


- Towards Efficient Image Compression Without Autoregressive Models [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/170dc3e41f2d03e327e04dbab0fccbfb-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=1ihGy9vAIg)]

- Memory-Efficient Fine-Tuning of Compressed Large Language Models via sub-4-bit Integer Quantization [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/7183f4fc87598f6c6e947b96714acbd6-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2305.14152)] [[paper with code](https://paperswithcode.com/paper/memory-efficient-fine-tuning-of-compressed)] [[openreview](https://openreview.net/forum?id=2jUKhUrBxP)]

- Lossy Image Compression with Conditional Diffusion Models [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ccf6d8b4a1fe9d9c8192f00c713872ea-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2209.06950)] [[paper with code](https://paperswithcode.com/paper/lossy-image-compression-with-conditional-1)] [[code](https://github.com/buggyyang/cdc_compression)] [[openreview](https://openreview.net/forum?id=QIBpzaDCAv)]


## CVPR-2023


- Efficient Hierarchical Entropy Model for Learned Point Cloud Compression [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Song_Efficient_Hierarchical_Entropy_Model_for_Learned_Point_Cloud_Compression_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/efficient-hierarchical-entropy-model-for)]


## ICLR-2023


- Quantized Compressed Sensing with Score-Based Generative Models [[paper](https://iclr.cc/virtual/2023/poster/11274)] [[arxiv](https://arxiv.org/abs/2211.13006)] [[paper with code](https://paperswithcode.com/paper/2211-13006)] [[code](https://github.com/mengxiangming/qcs-sgm)] [[openreview](https://openreview.net/forum?id=OOWLRfAI_V_)]

- MIMT: Masked Image Modeling Transformer for Video Compression [[paper](https://iclr.cc/virtual/2023/poster/11734)] [[openreview](https://openreview.net/forum?id=j9m-mVnndbm)]

- LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification [[paper](https://iclr.cc/virtual/2023/poster/11516)] [[arxiv](https://arxiv.org/abs/2204.02965)] [[paper with code](https://paperswithcode.com/paper/lilnetx-lightweight-networks-with-extreme)] [[code](https://github.com/sharath-girish/lilnetx)] [[openreview](https://openreview.net/forum?id=NVZvalzCLg)]


## ICCV-2023


- Lossy and Lossless (L2) Post-training Model Size Compression [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/lossy-and-lossless-l2-post-training-model)] [[code](https://github.com/modeltc/l2_compression)]

- Scene Matters: Model-based Deep Video Compression [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.04557)] [[paper with code](https://paperswithcode.com/paper/scene-matters-model-based-deep-video)]


## ICML-2023


- LoSparse: Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation [[paper](https://proceedings.mlr.press/v202/li23ap.html)] [[arxiv](https://arxiv.org/abs/2306.11222)] [[paper with code](https://paperswithcode.com/paper/losparse-structured-compression-of-large)]

- Less is More: Task-aware Layer-wise Distillation for Language Model Compression [[paper](https://proceedings.mlr.press/v202/liang23j.html)] [[arxiv](https://arxiv.org/abs/2210.01351)] [[paper with code](https://paperswithcode.com/paper/less-is-more-task-aware-layer-wise)] [[code](https://github.com/cliang1453/task-aware-distillation)]

- Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models [[paper](https://proceedings.mlr.press/v202/muckley23a.html)] [[arxiv](https://arxiv.org/abs/2301.11189)] [[paper with code](https://paperswithcode.com/paper/improving-statistical-fidelity-for-neural)]

- COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models [[paper](https://proceedings.mlr.press/v202/xiao23e.html)] [[arxiv](https://arxiv.org/abs/2305.17235)] [[paper with code](https://paperswithcode.com/paper/comcat-towards-efficient-compression-and)] [[code](https://github.com/jinqixiao/ComCAT)]


## ACL-2023


- Deep Model Compression Also Helps Models Capture Ambiguity [[paper](https://aclanthology.org/2023.acl-long.381/)] [[arxiv](https://arxiv.org/abs/2306.07061)] [[paper with code](https://paperswithcode.com/paper/deep-model-compression-also-helps-models)]

- AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression [[paper](https://aclanthology.org/2023.acl-long.471/)] [[arxiv](https://arxiv.org/abs/2305.10010)] [[paper with code](https://paperswithcode.com/paper/ad-kd-attribution-driven-knowledge)] [[code](https://github.com/brucewsy/ad-kd)]

- A Comparative Study on the Impact of Model Compression Techniques on Fairness in Language Models [[paper](https://aclanthology.org/2023.acl-long.878/)]

- Self-Distilled Quantization: Achieving High Compression Rates in Transformer-Based Language Models [[paper](https://aclanthology.org/2023.acl-short.114/)] [[arxiv](https://arxiv.org/abs/2307.05972)] [[paper with code](https://paperswithcode.com/paper/self-distilled-quantization-achieving-high)]


## IJCAI-2023


- Distilling Universal and Joint Knowledge for Cross-Domain Model Compression on Time Series Data [[paper](https://www.ijcai.org/proceedings/2023/496)] [[arxiv](https://arxiv.org/abs/2307.03347)] [[paper with code](https://paperswithcode.com/paper/distilling-universal-and-joint-knowledge-for)] [[code](https://github.com/ijcai2023/uni_kd)]


## AAAI-2023


- DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25543)]

- A Survey on Model Compression and Acceleration for Pretrained Language Models [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/26255)] [[arxiv](https://arxiv.org/abs/2202.07105)] [[paper with code](https://paperswithcode.com/paper/a-survey-on-model-compression-for-natural)]

- Lifelong Compression Mixture Model via Knowledge Relationship Graph [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/26292)]



# 2022


## NeurIPS-2022


- Weighted Mutual Learning with Diversity-Driven Model Compression [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/4b25c000967af9036fb9b207b198a626-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=UQJoGBNRX4)]

- Deep Compression of Pre-trained Transformer Models [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/5b5618e7d061748267d74478b7c5b1ab-Abstract-Conference.html)] [[openreview](https://openreview.net/forum?id=EZQnauHn-77)]

- Information-Theoretic GAN Compression with Variational Energy-based Model [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/7416573f05b50beac6d0aef3abc805c0-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2303.16050)] [[paper with code](https://paperswithcode.com/paper/information-theoretic-gan-compression-with)] [[openreview](https://openreview.net/forum?id=sRKNkpUMQNr)]

- Differentially Private Model Compression [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/bd6bb13e78da078d8adcabbe6d9ca737-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2206.01838)] [[paper with code](https://paperswithcode.com/paper/differentially-private-model-compression)] [[openreview](https://openreview.net/forum?id=68EuccCtO5i)]

- Model Preserving Compression for Neural Networks [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/f8928b073ccbec15d35f2a9d39430bfd-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2108.00065)] [[openreview](https://openreview.net/forum?id=gt-l9Hu2ndd)]


## CVPR-2022


- DiSparse: Disentangled Sparsification for Multitask Model Compression [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.04662)] [[paper with code](https://paperswithcode.com/paper/disparse-disentangled-sparsification-for-1)] [[code](https://github.com/shi-labs/disparse-multitask-model-compression)]

- CHEX: CHannel EXploration for CNN Model Compression [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.15794)] [[paper with code](https://paperswithcode.com/paper/chex-channel-exploration-for-cnn-model)] [[code](https://github.com/zejiangh/Filter-GaP)]

- Practical Learned Lossless JPEG Recompression With Multi-Level Cross-Channel Entropy Model in the DCT Domain [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.16357)] [[paper with code](https://paperswithcode.com/paper/practical-learned-lossless-jpeg-recompression)]


## ICLR-2022


- Entroformer: A Transformer-based Entropy Model for Learned Image Compression [[paper](https://iclr.cc/virtual/2022/poster/7022)] [[arxiv](https://arxiv.org/abs/2202.05492)] [[paper with code](https://paperswithcode.com/paper/entroformer-a-transformer-based-entropy-model-1)] [[code](https://github.com/mx54039q/entroformer)] [[openreview](https://openreview.net/forum?id=VrjOFfcnSV8)]

- Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression [[paper](https://iclr.cc/virtual/2022/poster/6553)] [[arxiv](https://arxiv.org/abs/2105.01869)] [[paper with code](https://paperswithcode.com/paper/sequential-encryption-of-sparse-neural)] [[openreview](https://openreview.net/forum?id=Vs5NK44aP9P)]

- Language model compression with weighted low-rank factorization [[paper](https://iclr.cc/virtual/2022/poster/6157)] [[arxiv](https://arxiv.org/abs/2207.00112)] [[paper with code](https://paperswithcode.com/paper/language-model-compression-with-weighted-low-1)] [[openreview](https://openreview.net/forum?id=uPv9Y3gmAI5)]

- Fast Generic Interaction Detection for Model Interpretability and Compression [[paper](https://iclr.cc/virtual/2022/poster/6556)] [[paper with code](https://paperswithcode.com/paper/fast-generic-interaction-detection-for-model)] [[openreview](https://openreview.net/forum?id=fQTlgI2qZqE)]

- Exploring extreme parameter compression for pre-trained language models [[paper](https://iclr.cc/virtual/2022/poster/6449)] [[arxiv](https://arxiv.org/abs/2205.10036)] [[paper with code](https://paperswithcode.com/paper/exploring-extreme-parameter-compression-for-1)] [[code](https://github.com/twinkle0331/xcompression)] [[openreview](https://openreview.net/forum?id=RftryyYyjiG)]


## ECCV-2022


- Contextformer: A Transformer with Spatio-Channel Attention for Context Modeling in Learned Image Compression [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6046_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2203.02452)] [[paper with code](https://paperswithcode.com/paper/contextformer-a-transformer-with-spatio)]

- Point Cloud Compression with Range Image-Based Entropy Model for Autonomous Driving [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3885_ECCV_2022_paper.php)]


## ICML-2022


- History Compression via Language Models in Reinforcement Learning [[paper](https://proceedings.mlr.press/v162/paischer22a.html)] [[arxiv](https://arxiv.org/abs/2205.12258)] [[paper with code](https://paperswithcode.com/paper/history-compression-via-language-models-in)] [[code](https://github.com/ml-jku/helm)]

- Uncertainty Modeling in Generative Compressed Sensing [[paper](https://proceedings.mlr.press/v162/zhang22ai.html)]


## ACL-2022


- Multi-Granularity Structural Knowledge Distillation for Language Model Compression [[paper](https://aclanthology.org/2022.acl-long.71/)] [[paper with code](https://paperswithcode.com/paper/multi-granularity-structural-knowledge)] [[code](https://github.com/lc97-pku/mgskd)]

- Compression of Generative Pre-trained Language Models via Quantization [[paper](https://aclanthology.org/2022.acl-long.331/)] [[arxiv](https://arxiv.org/abs/2203.10705)] [[paper with code](https://paperswithcode.com/paper/compression-of-generative-pre-trained)]


## AAAI-2022


- OctAttention: Octree-Based Large-Scale Contexts Model for Point Cloud Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/19942)] [[arxiv](https://arxiv.org/abs/2202.06028)] [[paper with code](https://paperswithcode.com/paper/octattention-octree-based-large-scale)] [[code](https://github.com/zb12138/octattention)]

- From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/21408)] [[arxiv](https://arxiv.org/abs/2112.07198)] [[paper with code](https://paperswithcode.com/paper/from-dense-to-sparse-contrastive-pruning-for)] [[code](https://github.com/alibaba/AliceMind)]



# 2021


## NeurIPS-2021


- Preserved central model for faster bidirectional compression in distributed settings [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/13d63838ef1fb6f34ca2dc6821c60e49-Abstract.html)] [[arxiv](https://arxiv.org/abs/2102.12528)] [[paper with code](https://paperswithcode.com/paper/preserved-central-model-for-faster)] [[code](https://github.com/philipco/mcm-bidirectional-compression)] [[openreview](https://openreview.net/forum?id=q6h7jVe0wE3)]

- OSOA: One-Shot Online Adaptation of Deep Generative Models for Lossless Compression [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/a2915ad0d57ca8c644f99f9c3f20a918-Abstract.html)] [[arxiv](https://arxiv.org/abs/2111.01662)] [[paper with code](https://paperswithcode.com/paper/osoa-one-shot-online-adaptation-of-deep)] [[openreview](https://openreview.net/forum?id=Me-tuhUjhKK)]

- DRONE: Data-aware Low-rank Compression for Large NLP Models [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/f56de5ef149cf0aedcc8f4797031e229-Abstract.html)] [[paper with code](https://paperswithcode.com/paper/drone-data-aware-low-rank-compression-for)] [[openreview](https://openreview.net/forum?id=sthiz9zeXGG)]


## CVPR-2021


- Towards Efficient Tensor Decomposition-Based DNN Model Compression With Optimization Framework [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Towards_Efficient_Tensor_Decomposition-Based_DNN_Model_Compression_With_Optimization_Framework_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2107.12422)] [[paper with code](https://paperswithcode.com/paper/towards-efficient-tensor-decomposition-based-1)]

- Checkerboard Context Model for Efficient Learned Image Compression [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/He_Checkerboard_Context_Model_for_Efficient_Learned_Image_Compression_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.15306)] [[paper with code](https://paperswithcode.com/paper/checkerboard-context-model-for-efficient)] [[code](https://github.com/JiangWeibeta/Checkerboard-Context-Model-for-Efficient-Learned-Image-Compression)]


## ICLR-2021


- Training with Quantization Noise for Extreme Model Compression [[paper](https://iclr.cc/virtual/2021/poster/2772)] [[arxiv](https://arxiv.org/abs/2004.07320)] [[paper with code](https://paperswithcode.com/paper/training-with-quantization-noise-for-extreme)] [[code](https://github.com/pytorch/fairseq)] [[openreview](https://openreview.net/forum?id=dV19Yyi1fS3)]

- Lossless Compression of Structured Convolutional Models via Lifting [[paper](https://iclr.cc/virtual/2021/poster/2929)] [[arxiv](https://arxiv.org/abs/2007.06567)] [[paper with code](https://paperswithcode.com/paper/lossless-compression-of-structured)] [[code](https://github.com/GustikS/NeuraLogic)] [[openreview](https://openreview.net/forum?id=oxnp2q-PGL4)]

- Learning Accurate Entropy Model with Global Reference for Image Compression [[paper](https://iclr.cc/virtual/2021/poster/2829)] [[arxiv](https://arxiv.org/abs/2010.08321)] [[paper with code](https://paperswithcode.com/paper/learning-accurate-entropy-model-with-global-1)] [[code](https://github.com/damo-cv/img-comp-reference)] [[openreview](https://openreview.net/forum?id=cTbIjyrUVwJ)]

- UMEC: Unified model and embedding compression for efficient recommendation systems [[paper](https://iclr.cc/virtual/2021/poster/2976)] [[paper with code](https://paperswithcode.com/paper/umec-unified-model-and-embedding-compression)] [[openreview](https://openreview.net/forum?id=BM---bH_RSh)]

- Hierarchical Autoregressive Modeling for Neural Video Compression [[paper](https://iclr.cc/virtual/2021/poster/2626)] [[arxiv](https://arxiv.org/abs/2010.10258)] [[paper with code](https://paperswithcode.com/paper/hierarchical-autoregressive-modeling-for-1)] [[code](https://github.com/buggyyang/youtube-nt)] [[openreview](https://openreview.net/forum?id=TK_6nNb_C7q)]


## ICCV-2021


- Exploration and Estimation for Model Compression [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Exploration_and_Estimation_for_Model_Compression_ICCV_2021_paper.html)]


## ACL-2021


- Meta-KD: A Meta Knowledge Distillation Framework for Language Model Compression across Domains [[paper](https://aclanthology.org/2021.acl-long.236/)] [[arxiv](https://arxiv.org/abs/2012.01266)] [[paper with code](https://paperswithcode.com/paper/meta-kd-a-meta-knowledge-distillation)] [[code](https://github.com/alibaba/EasyNLP)]

- Enabling Lightweight Fine-tuning for Pre-trained Language Model Compression based on Matrix Product Operators [[paper](https://aclanthology.org/2021.acl-long.418/)] [[arxiv](https://arxiv.org/abs/2106.02205)] [[paper with code](https://paperswithcode.com/paper/enabling-lightweight-fine-tuning-for-pre)] [[code](https://github.com/RUCAIBox/MPOP)]

- Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization [[paper](https://aclanthology.org/2021.acl-long.510/)] [[arxiv](https://arxiv.org/abs/2105.12002)] [[paper with code](https://paperswithcode.com/paper/super-tickets-in-pre-trained-language-models)] [[code](https://github.com/cliang1453/super-structured-lottery-tickets)]


## AAAI-2021


- Robust Model Compression Using Deep Hypotheses [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16827)] [[arxiv](https://arxiv.org/abs/2103.07668)] [[paper with code](https://paperswithcode.com/paper/robust-model-compression-using-deep)] [[code](https://github.com/TAU-MLwell/Rubust-Model-Compression)]

- Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16859)] [[arxiv](https://arxiv.org/abs/2012.08749)] [[paper with code](https://paperswithcode.com/paper/provable-benefits-of-overparameterization-in)]



# 2020


## NeurIPS-2020


- Robust compressed sensing using generative models [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/07cb5f86508f146774a2fac4373a8e50-Abstract.html)] [[arxiv](https://arxiv.org/abs/2006.09461)]

- MuSCLE: Multi Sweep Compression of LiDAR using Deep Entropy Models [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/fc152e73692bc3c934d248f639d9e963-Abstract.html)] [[arxiv](https://arxiv.org/abs/2011.07590)] [[paper with code](https://paperswithcode.com/paper/muscle-multi-sweep-compression-of-lidar-using-1)]


## CVPR-2020


- Discrete Model Compression With Resource Constraint for Deep Neural Networks [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Gao_Discrete_Model_Compression_With_Resource_Constraint_for_Deep_Neural_Networks_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/discrete-model-compression-with-resource)]

- Multi-Dimensional Pruning: A Unified Framework for Model Compression [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Guo_Multi-Dimensional_Pruning_A_Unified_Framework_for_Model_Compression_CVPR_2020_paper.html)] [[paper with code](https://paperswithcode.com/paper/multi-dimensional-pruning-a-unified-framework)]

- Towards Efficient Model Compression via Learned Global Ranking [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Chin_Towards_Efficient_Model_Compression_via_Learned_Global_Ranking_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1904.12368)] [[paper with code](https://paperswithcode.com/paper/legr-filter-pruning-via-learned-global)] [[code](https://github.com/cmu-enyac/LeGR)]

- OctSqueeze: Octree-Structured Entropy Model for LiDAR Compression [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Huang_OctSqueeze_Octree-Structured_Entropy_Model_for_LiDAR_Compression_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2005.07178)] [[paper with code](https://paperswithcode.com/paper/octsqueeze-octree-structured-entropy-model)] [[code](https://github.com/mindspore-ai/models/tree/master/official/cv/octsqueeze)]

- The Knowledge Within: Methods for Data-Free Model Compression [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Haroush_The_Knowledge_Within_Methods_for_Data-Free_Model_Compression_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1912.01274)] [[paper with code](https://paperswithcode.com/paper/the-knowledge-within-methods-for-data-free)]

- Structured Multi-Hashing for Model Compression [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Eban_Structured_Multi-Hashing_for_Model_Compression_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/1911.11177)] [[paper with code](https://paperswithcode.com/paper/structured-multi-hashing-for-model)]


## ICLR-2020


- Scalable Model Compression by Entropy Penalized Reparameterization [[paper](https://iclr.cc/virtual/2020/poster/1811)] [[arxiv](https://arxiv.org/abs/1906.06624)] [[paper with code](https://paperswithcode.com/paper/model-compression-by-entropy-penalized)] [[openreview](https://openreview.net/forum?id=HkgxW0EYDS)]

- HiLLoC: lossless image compression with hierarchical latent variable models [[paper](https://iclr.cc/virtual/2020/poster/2008)] [[arxiv](https://arxiv.org/abs/1912.09953)] [[paper with code](https://paperswithcode.com/paper/hilloc-lossless-image-compression-with-1)] [[code](https://github.com/hilloc-submission/hilloc)] [[openreview](https://openreview.net/forum?id=r1lZgyBYwS)]


## ECCV-2020


- Online Ensemble Model Compression using Knowledge Distillation [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3136_ECCV_2020_paper.php)] [[arxiv](https://arxiv.org/abs/2011.07449)]

- High-quality Single-model Deep Video Compression with Frame-Conv3D and Multi-frame Differential Modulation [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/7358_ECCV_2020_paper.php)]


## ICML-2020


- Evaluating Lossy Compression Rates of Deep Generative Models [[paper](https://proceedings.mlr.press/v119/huang20c.html)] [[arxiv](https://arxiv.org/abs/2008.06653)] [[paper with code](https://paperswithcode.com/paper/evaluating-lossy-compression-rates-of-deep)] [[code](https://github.com/BorealisAI/rate_distortion)]

- On the Power of Compressed Sensing with Generative Models [[paper](https://proceedings.mlr.press/v119/kamath20a.html)] [[paper with code](https://paperswithcode.com/paper/on-the-power-of-compressed-sensing-with)]


## AAAI-2020


- Information-Theoretic Understanding of Population Risk Improvement with Model Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/5730)] [[arxiv](https://arxiv.org/abs/1901.09421)] [[paper with code](https://paperswithcode.com/paper/information-theoretic-understanding-of)] [[code](https://github.com/wgao9/weight_quant)]

- Light Multi-Segment Activation for Model Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6128)] [[arxiv](https://arxiv.org/abs/1907.06870)] [[paper with code](https://paperswithcode.com/paper/light-multi-segment-activation-for-model)] [[code](https://github.com/LMA-NeurIPS19/LMA)]

- Coarse-to-Fine Hyper-Prior Modeling for Learned Image Compression [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6736)]



# 2019


## NeurIPS-2019


- Model Compression with Adversarial Robustness: A Unified Optimization Framework [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/2ca65f58e35d9ad45bf7f3ae5cfd08f1-Abstract.html)] [[arxiv](https://arxiv.org/abs/1902.03538)] [[paper with code](https://paperswithcode.com/paper/adversarially-trained-model-compression-when)] [[code](https://github.com/shupenggui/ATMC)]


## CVPR-2019


- ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_ComDefend_An_Efficient_Image_Compression_Model_to_Defend_Adversarial_Examples_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1811.12673)] [[paper with code](https://paperswithcode.com/paper/comdefend-an-efficient-image-compression)] [[code](https://github.com/jiaxiaojunQAQ/Comdefend)]

- Cross Domain Model Compression by Structurally Weight Sharing [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Cross_Domain_Model_Compression_by_Structurally_Weight_Sharing_CVPR_2019_paper.html)] [[paper with code](https://paperswithcode.com/paper/cross-domain-model-compression-by)]

- ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_ECC_Platform-Independent_Energy-Constrained_Deep_Neural_Network_Compression_via_a_Bilinear_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1812.01803)] [[paper with code](https://paperswithcode.com/paper/ecc-energy-constrained-deep-neural-network)] [[code](https://github.com/hyang1990/energy_constrained_compression)]


## ICLR-2019


- Context-adaptive Entropy Model for End-to-end Optimized Image Compression [[paper](https://openreview.net/forum?id=HyxKIiAqYQ)] [[arxiv](https://arxiv.org/abs/1809.10452)] [[paper with code](https://paperswithcode.com/paper/context-adaptive-entropy-model-for-end-to-end)] [[code](https://github.com/JooyoungLeeETRI/CA_Entropy_Model)] [[openreview](https://openreview.net/forum?id=HyxKIiAqYQ)]

- Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters [[paper](https://openreview.net/forum?id=r1f0YiCctm)] [[arxiv](https://arxiv.org/abs/1810.00440)] [[paper with code](https://paperswithcode.com/paper/minimal-random-code-learning-getting-bits)] [[code](https://github.com/cambridge-mlg/miracle)] [[openreview](https://openreview.net/forum?id=r1f0YiCctm)]

- Integer Networks for Data Compression with Latent-Variable Models [[paper](https://openreview.net/forum?id=S1zz2i0cY7)] [[paper with code](https://paperswithcode.com/paper/integer-networks-for-data-compression-with)] [[openreview](https://openreview.net/forum?id=S1zz2i0cY7)]


## ICCV-2019


- Adversarial Robustness vs. Model Compression, or Both? [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Ye_Adversarial_Robustness_vs._Model_Compression_or_Both_ICCV_2019_paper.html)] [[paper with code](https://paperswithcode.com/paper/adversarial-robustness-vs-model-compression)] [[code](https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM)]


## ICML-2019


- Rate Distortion For Model Compression:From Theory To Practice [[paper](https://proceedings.mlr.press/v97/gao19c.html)]

- LIT: Learned Intermediate Representation Training for Model Compression [[paper](https://proceedings.mlr.press/v97/koratana19a.html)] [[paper with code](https://paperswithcode.com/paper/lit-learned-intermediate-representation)] [[code](https://github.com/stanford-futuredata/lit-code)]


## IJCAI-2019


- Play and Prune: Adaptive Filter Pruning for Deep Model Compression [[paper](https://www.ijcai.org/proceedings/2019/480)] [[arxiv](https://arxiv.org/abs/1905.04446)] [[paper with code](https://paperswithcode.com/paper/play-and-prune-adaptive-filter-pruning-for)] [[code](https://github.com/softsys4ai/neural-distiller)]

- COP: Customized Deep Model Compression via Regularized Correlation-Based Filter-Level Pruning [[paper](https://www.ijcai.org/proceedings/2019/525)] [[arxiv](https://arxiv.org/abs/1906.10337)] [[paper with code](https://paperswithcode.com/paper/cop-customized-deep-model-compression-via)] [[code](https://github.com/ZJULearning/COP)]


## AAAI-2019


- Private Model Compression via Knowledge Distillation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/3913)] [[arxiv](https://arxiv.org/abs/1811.05072)] [[paper with code](https://paperswithcode.com/paper/private-model-compression-via-knowledge)]


# 2018


## NeurIPS-2018


- Deep Generative Models for Distribution-Preserving Lossy Compression [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/801fd8c2a4e79c1d24a40dc735c051ae-Abstract.html)] [[arxiv](https://arxiv.org/abs/1805.11057)] [[paper with code](https://paperswithcode.com/paper/deep-generative-models-for-distribution)] [[code](https://github.com/mitscha/dplc)]


## CVPR-2018


- Conditional Probability Models for Deep Image Compression [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Mentzer_Conditional_Probability_Models_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1801.04260)] [[paper with code](https://paperswithcode.com/paper/conditional-probability-models-for-deep-image)] [[code](https://github.com/fab-jul/imgcomp-cvpr)]


## ICLR-2018


- Model compression via distillation and quantization [[paper](https://openreview.net/forum?id=S1XolQbRW)] [[arxiv](https://arxiv.org/abs/1802.05668)] [[paper with code](https://paperswithcode.com/paper/model-compression-via-distillation-and)] [[code](https://github.com/antspy/quantized_distillation)] [[openreview](https://openreview.net/forum?id=S1XolQbRW)]


## ECCV-2018


- AMC: AutoML for Model Compression and Acceleration on Mobile Devices [[paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/html/Yihui_He_AMC_Automated_Model_ECCV_2018_paper.php)] [[arxiv](https://arxiv.org/abs/1802.03494)] [[paper with code](https://paperswithcode.com/paper/amc-automl-for-model-compression-and)] [[code](https://github.com/mit-han-lab/amc)]


## ICML-2018


- Modeling Sparse Deviations for Compressed Sensing using Generative Models [[paper](https://proceedings.mlr.press/v80/dhar18a.html)] [[arxiv](https://arxiv.org/abs/1807.01442)] [[paper with code](https://paperswithcode.com/paper/modeling-sparse-deviations-for-compressed)] [[code](https://github.com/aditya-grover/uae)]


## ACL-2018


- A Language Model based Evaluator for Sentence Compression [[paper](https://aclanthology.org/P18-2028/)] [[paper with code](https://paperswithcode.com/paper/a-language-model-based-evaluator-for-sentence)]