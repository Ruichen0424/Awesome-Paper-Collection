# Awesome 3D Generation Paper Collection

- [2024](#2024)
  - [AAAI](#aaai-2024)

- [2023](#2023)
  - [NeurIPS](#neurips-2023)
  - [CVPR](#cvpr-2023)
  - [ICCV](#iccv-2023)
  - [ICML](#icml-2023)
  - [AAAI](#aaai-2023)

- [2022](#2022)
  - [NeurIPS](#neurips-2022)
  - [CVPR](#cvpr-2022)
  - [ECCV](#eccv-2022)
  - [ICML](#icml-2022)
  - [AAAI](#aaai-2022)

- [2021](#2021)
  - [NeurIPS](#neurips-2021)
  - [CVPR](#cvpr-2021)
  - [ICCV](#iccv-2021)
  - [AAAI](#aaai-2021)

- [2020](#2020)
  - [NeurIPS](#neurips-2020)
  - [CVPR](#cvpr-2020)
  - [AAAI](#aaai-2020)

- [2019](#2019)
  - [NeurIPS](#neurips-2019)
  - [CVPR](#cvpr-2019)
  - [ICCV](#iccv-2019)

- [2018](#2018)
  - [NeurIPS](#neurips-2018)
  - [CVPR](#cvpr-2018)
  - [AAAI](#aaai-2018)



# 2024


## AAAI-2024


- Explore 3D Dance Generation via Reward Model from Automatically-Ranked Demonstrations [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27783)] [[arxiv](https://arxiv.org/abs/2312.11442)] [[paper with code](https://paperswithcode.com/paper/explore-3d-dance-generation-via-reward-model)]

- Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27787)] [[arxiv](https://arxiv.org/abs/2401.02683)] [[paper with code](https://paperswithcode.com/paper/geometric-facilitated-denoising-diffusion)] [[code](https://github.com/LEOXC1571/GFMDiff)]

- Real3D: The Curious Case of Neural Scene Degeneration [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27863)]

- IT3D: Improved Text-to-3D Generation with Explicit View Synthesis [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27886)] [[arxiv](https://arxiv.org/abs/2308.11473)] [[paper with code](https://paperswithcode.com/paper/it3d-improved-text-to-3d-generation-with)] [[code](https://github.com/buaacyw/it3d-text-to-3d)]

- ContactGen: Contact-Guided Interactive 3D Human Generation for Partners [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/27962)] [[arxiv](https://arxiv.org/abs/2401.17212)] [[paper with code](https://paperswithcode.com/paper/contactgen-contact-guided-interactive-3d)]

- SGFormer: Semantic Graph Transformer for Point Cloud-Based 3D Scene Graph Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28197)] [[arxiv](https://arxiv.org/abs/2303.11048)] [[paper with code](https://paperswithcode.com/paper/revisiting-transformer-for-point-cloud-based)]

- Controllable 3D Face Generation with Conditional Style Code Diffusion [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28283)] [[arxiv](https://arxiv.org/abs/2312.13941)] [[paper with code](https://paperswithcode.com/paper/controllable-3d-face-generation-with)] [[code](https://github.com/sxl142/tex-face)]

- Diverse and Stable 2D Diffusion Guided Text to 3D Generation with Noise Recalibration [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28476)]



# 2023


## NeurIPS-2023


- Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/01d64478381c33e29ed611f1719f5a37-Abstract-Conference.html)]

- ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/0b68d474baf8dff30f3280c199a32089-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2311.05230)] [[paper with code](https://paperswithcode.com/paper/conrad-image-constrained-radiance-fields-for)] [[openview](https://openreview.net/forum?id=roGYQvarnC)]

- ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1a87980b9853e84dfb295855b425c262-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2305.16213)] [[paper with code](https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse)] [[code](https://github.com/threestudio-project/threestudio)] [[openview](https://openreview.net/forum?id=ppJuFSOAnM)]

- Debiasing Scores and Prompts of 2D Diffusion for View-consistent Text-to-3D Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/27725882a88f202e07319abbb3be7693-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2303.15413)] [[paper with code](https://paperswithcode.com/paper/debiasing-scores-and-prompts-of-2d-diffusion)] [[code](https://github.com/threestudio-project/threestudio)] [[openview](https://openreview.net/forum?id=jgIrJeHHlz)]

- PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2c575c088de5cfef858b8837251f3027-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2312.04559)] [[paper with code](https://paperswithcode.com/paper/primdiffusion-volumetric-primitives-diffusion-1)] [[code](https://github.com/frozenburning/primdiffusion)] [[openview](https://openreview.net/forum?id=ESCafo3oD5)]

- VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/54d2d38a56a74387d5916ee40e462295-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2307.16605)] [[paper with code](https://paperswithcode.com/paper/vpp-efficient-conditional-3d-generation-via)] [[code](https://github.com/qizekun/vpp)] [[openview](https://openreview.net/forum?id=etd0ebzGOG)]

- XAGen: 3D Expressive Human Avatars Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/6d6f9908ea35313dd7566f5ce8c6e815-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2311.13574)] [[paper with code](https://paperswithcode.com/paper/xagen-3d-expressive-human-avatars-generation)] [[openview](https://openreview.net/forum?id=eUf0CaS5AP)]

- Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/73af055566f5514b9863315133b84eda-Abstract-Conference.html)]

- DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d6c01b025cad37d5c8bab4ba18846c02-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2307.01831)] [[paper with code](https://paperswithcode.com/paper/dit-3d-exploring-plain-diffusion-transformers-1)] [[code](https://github.com/DiT-3D/DiT-3D)] [[openview](https://openreview.net/forum?id=Se71ks7Mfz)]

- 3D molecule generation by denoising voxel grids [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/da1131a86ac3c70e0b7cae89c3d4df22-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.07473)] [[paper with code](https://paperswithcode.com/paper/3d-molecule-generation-by-denoising-voxel)] [[code](https://github.com/genentech/voxmol)] [[openview](https://openreview.net/forum?id=Zyzluw0hC4)]

- Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ea1a7f7bc0fc14142106a84c94c826d0-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2306.17115)] [[paper with code](https://paperswithcode.com/paper/michelangelo-conditional-3d-shape-generation-1)] [[code](https://github.com/neuralcarver/michelangelo)] [[openview](https://openreview.net/forum?id=xmxgMij3LY)]


## CVPR-2023


- Patch-Based 3D Natural Scene Generation From a Single Example [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Patch-Based_3D_Natural_Scene_Generation_From_a_Single_Example_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.12670)] [[paper with code](https://paperswithcode.com/paper/patch-based-3d-natural-scene-generation-from)]

- SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Cheng_SDFusion_Multimodal_3D_Shape_Completion_Reconstruction_and_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.04493)] [[paper with code](https://paperswithcode.com/paper/sdfusion-multimodal-3d-shape-completion)] [[code](https://github.com/yccyenchicheng/SDFusion)]

- 3D Neural Field Generation Using Triplane Diffusion [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Shue_3D_Neural_Field_Generation_Using_Triplane_Diffusion_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.16677)] [[paper with code](https://paperswithcode.com/paper/3d-neural-field-generation-using-triplane)]

- High-Fidelity 3D Face Generation From Natural Language Descriptions [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_High-Fidelity_3D_Face_Generation_From_Natural_Language_Descriptions_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.03302)] [[paper with code](https://paperswithcode.com/paper/high-fidelity-3d-face-generation-from-natural)] [[code](https://github.com/zhuhao-nju/describe3d)]

- Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Score_Jacobian_Chaining_Lifting_Pretrained_2D_Diffusion_Models_for_3D_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.00774)] [[paper with code](https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d)] [[code](https://github.com/pals-ttic/sjc)]

- OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_OmniObject3D_Large-Vocabulary_3D_Object_Dataset_for_Realistic_Perception_Reconstruction_and_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2301.07525)] [[paper with code](https://paperswithcode.com/paper/omniobject3d-large-vocabulary-3d-object)] [[code](https://github.com/omniobject3d/omniobject3d)]

- RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.09869)] [[paper with code](https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d)] [[code](https://github.com/anciukevicius/renderdiffusion)]

- Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Metzer_Latent-NeRF_for_Shape-Guided_Generation_of_3D_Shapes_and_Textures_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2211.07600)] [[paper with code](https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d)] [[code](https://github.com/eladrich/latent-nerf)]

- Diffusion-Based Signed Distance Fields for 3D Shape Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Shim_Diffusion-Based_Signed_Distance_Fields_for_3D_Shape_Generation_CVPR_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/diffusion-based-signed-distance-fields-for-3d)]

- MIME: Human-Aware 3D Scene Generation [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yi_MIME_Human-Aware_3D_Scene_Generation_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.04360)] [[paper with code](https://paperswithcode.com/paper/mime-human-aware-3d-scene-generation)]

- Diffusion-Based Generation, Optimization, and Planning in 3D Scenes [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Diffusion-Based_Generation_Optimization_and_Planning_in_3D_Scenes_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2301.06015)] [[paper with code](https://paperswithcode.com/paper/diffusion-based-generation-optimization-and)] [[code](https://github.com/scenediffuser/Scene-Diffuser)]

- TAPS3D: Text-Guided 3D Textured Shape Generation From Pseudo Supervision [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_TAPS3D_Text-Guided_3D_Textured_Shape_Generation_From_Pseudo_Supervision_CVPR_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13273)] [[paper with code](https://paperswithcode.com/paper/taps3d-text-guided-3d-textured-shape)] [[code](https://github.com/plusmultiply/taps3d)]


## ICCV-2023


- Texture Generation on 3D Meshes with Point-UV Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.10490)] [[paper with code](https://paperswithcode.com/paper/texture-generation-on-3d-meshes-with-point-uv)]

- Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.09662)] [[paper with code](https://paperswithcode.com/paper/make-an-animation-large-scale-text)]

- CC3D: Layout-Conditioned Generation of Compositional 3D Scenes [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.12074)] [[paper with code](https://paperswithcode.com/paper/cc3d-layout-conditioned-generation-of)]

- DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2305.01921)] [[paper with code](https://paperswithcode.com/paper/difffacto-controllable-part-based-3d-point)]

- 3D-aware Image Generation using 2D Diffusion Models [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.17905)] [[paper with code](https://paperswithcode.com/paper/3d-aware-image-generation-using-2d-diffusion)]

- PG-RCNN: Semantic Surface Point Generation for 3D Object Detection [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2307.12637)] [[paper with code](https://paperswithcode.com/paper/pg-rcnn-semantic-surface-point-generation-for)] [[code](https://github.com/quotation2520/pg-rcnn)]

- Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.06714)] [[paper with code](https://paperswithcode.com/paper/single-stage-diffusion-nerf-a-unified)] [[code](https://github.com/Lakonik/SSDNeRF)]

- 3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.07378)] [[paper with code](https://paperswithcode.com/paper/3dhumangan-towards-photo-realistic-3d-aware)] [[code](https://github.com/3dhumangan/3dhumangan)]

- 3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.07546)] [[paper with code](https://paperswithcode.com/paper/3dhacker-spectrum-based-decision-boundary)]

- DreamBooth3D: Subject-Driven Text-to-3D Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.13508)] [[paper with code](https://paperswithcode.com/paper/dreambooth3d-subject-driven-text-to-3d)]

- ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2203.07706)] [[paper with code](https://paperswithcode.com/paper/actformer-a-gan-transformer-framework-towards)]

- SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2303.12236)] [[paper with code](https://paperswithcode.com/paper/salad-part-level-latent-diffusion-for-3d)]

- HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.11261)] [[paper with code](https://paperswithcode.com/paper/hmd-nemo-online-3d-avatar-motion-generation)]

- Generative Multiplane Neural Radiance for 3D-Aware Image Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.01172)] [[paper with code](https://paperswithcode.com/paper/generative-multiplane-neural-radiance-for-3d)] [[code](https://github.com/virobo-15/gmnr)]

- FineDance: A Fine-grained Choreography Dataset for 3D Full Body Dance Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2212.03741)] [[paper with code](https://paperswithcode.com/paper/magic-multi-art-genre-intelligent)] [[code](https://github.com/li-ronghui/FineDance)]

- Learning Versatile 3D Shape Generation with Improved Auto-regressive Models [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-versatile-3d-shape-generation-with-1)]

- TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.02419)] [[paper with code](https://paperswithcode.com/paper/tm2d-bimodality-driven-3d-dance-generation)] [[code](https://github.com/Garfield-kh/TM2D)]

- ShapeScaffolder: Structure-Aware 3D Shape Generation from Text [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.html)] [[paper with code](https://paperswithcode.com/paper/shapescaffolder-structure-aware-3d-shape)]

- GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2206.07255)] [[paper with code](https://paperswithcode.com/paper/gram-hd-3d-consistent-image-generation-at)]

- SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2304.10417)] [[paper with code](https://paperswithcode.com/paper/sinc-spatial-composition-of-3d-human-motions)]

- Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation Using only Images [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.html)] [[arxiv](https://arxiv.org/abs/2308.16758)] [[paper with code](https://paperswithcode.com/paper/towards-high-fidelity-text-guided-3d-face)]


## ICML-2023


- MolDiff: Addressing the Atom-Bond Inconsistency Problem in 3D Molecule Diffusion Generation [[paper](https://proceedings.mlr.press/v202/peng23b.html)] [[arxiv](https://arxiv.org/abs/2305.07508)] [[paper with code](https://paperswithcode.com/paper/moldiff-addressing-the-atom-bond)] [[code](https://github.com/pengxingang/moldiff)]

- Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D [[paper](https://proceedings.mlr.press/v202/qiang23a.html)] [[arxiv](https://arxiv.org/abs/2305.13266)] [[paper with code](https://paperswithcode.com/paper/coarse-to-fine-a-hierarchical-diffusion-model)] [[code](https://github.com/qiangbo1222/hierdiff)]

- Geometric Latent Diffusion Models for 3D Molecule Generation [[paper](https://proceedings.mlr.press/v202/xu23n.html)] [[arxiv](https://arxiv.org/abs/2305.01140)] [[paper with code](https://paperswithcode.com/paper/geometric-latent-diffusion-models-for-3d)] [[code](https://github.com/minkaixu/geoldm)]


## AAAI-2023


- 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25186)] [[arxiv](https://arxiv.org/abs/2212.01103)] [[paper with code](https://paperswithcode.com/paper/3d-togo-towards-text-guided-cross-category-3d)]

- Pose-Guided 3D Human Generation in Indoor Scene [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25195)]

- MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25206)] [[arxiv](https://arxiv.org/abs/2212.05897)] [[paper with code](https://paperswithcode.com/paper/multiact-long-term-3d-human-motion-generation)] [[code](https://github.com/TaeryungLee/MultiAct_RELEASE)]

- CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25214)]

- MDM: Molecular Diffusion Model for 3D Molecule Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25639)] [[arxiv](https://arxiv.org/abs/2209.05710)] [[paper with code](https://paperswithcode.com/paper/mdm-molecular-diffusion-model-for-3d-molecule)]



# 2022


## NeurIPS-2022


- ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3a33ae4d634b49b0866b4142a1f82a2f-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2207.09446)] [[paper with code](https://paperswithcode.com/paper/shapecrafter-a-recursive-text-conditioned-3d)] [[code](https://github.com/FreddieRao/ShapeCrafter)]

- LION: Latent Point Diffusion Models for 3D Shape Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/40e56dabe12095a5fc44a6e4c3835948-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.06978)] [[paper with code](https://paperswithcode.com/paper/lion-latent-point-diffusion-models-for-3d)] [[code](https://github.com/nv-tlabs/LION)]

- HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6030db5195150ac86d942186f4abdad8-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.09729)] [[paper with code](https://paperswithcode.com/paper/humanise-language-conditioned-human-motion)] [[code](https://github.com/Silverster98/HUMANISE)]

- SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/8ae9cf363ea625161f885b798c1f1f78-Abstract-Conference.html)]

- GAUDI: A Neural Architect for Immersive 3D Scene Generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/a03037317560b8c5f2fb4b6466d4c439-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2207.13751)] [[paper with code](https://paperswithcode.com/paper/gaudi-a-neural-architect-for-immersive-3d)] [[code](https://github.com/apple/ml-gaudi)]

- AniFaceGAN: Animatable 3D-Aware Face Image Generation for Video Avatars [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/eae78bf2712f222f101bd7d12f875a57-Abstract-Conference.html)] [[arxiv](https://arxiv.org/abs/2210.06465)] [[paper with code](https://paperswithcode.com/paper/anifacegan-animatable-3d-aware-face-image)] [[code](https://github.com/YueWuHKUST/AniFaceGAN)]


## CVPR-2022


- Neural Template: Topology-Aware Reconstruction and Disentangled Generation of 3D Meshes [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2206.04942)] [[paper with code](https://paperswithcode.com/paper/neural-template-topology-aware-reconstruction-1)] [[code](https://github.com/edward1997104/Neural-Template)]

- AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.09516)] [[paper with code](https://paperswithcode.com/paper/autosdf-shape-priors-for-3d-completion)] [[code](https://github.com/yccyenchicheng/AutoSDF)]

- Towards Implicit Text-Guided 3D Shape Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.14622)] [[paper with code](https://paperswithcode.com/paper/towards-implicit-text-guided-3d-shape)] [[code](https://github.com/liuzhengzhe/towards-implicit-text-guided-shape-generation)]

- StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.11427)] [[paper with code](https://paperswithcode.com/paper/stylesdf-high-resolution-3d-consistent-image)] [[code](https://github.com/royorel/StyleSDF)]

- Bailando: 3D Dance Generation by Actor-Critic GPT With Choreographic Memory [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.13055)] [[paper with code](https://paperswithcode.com/paper/bailando-3d-dance-generation-by-actor-critic)] [[code](https://github.com/lisiyao21/bailando)]

- Sparse to Dense Dynamic 3D Facial Expression Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2105.07463)] [[paper with code](https://paperswithcode.com/paper/3d-to-4d-facial-expressions-generation-guided)]

- WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.12917)] [[paper with code](https://paperswithcode.com/paper/warpinggan-warping-multiple-uniform-priors)] [[code](https://github.com/yztang4/warpinggan)]

- GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.08867)] [[paper with code](https://paperswithcode.com/paper/gram-generative-radiance-manifolds-for-3d)]

- FLAG: Flow-Based 3D Avatar Generation From Sparse Observations [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2203.05789)] [[paper with code](https://paperswithcode.com/paper/flag-flow-based-3d-avatar-generation-from)]

- AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.html)] [[arxiv](https://arxiv.org/abs/2112.11593)] [[paper with code](https://paperswithcode.com/paper/adaptpose-cross-dataset-adaptation-for-3d)] [[code](https://github.com/mgholamikn/AdaptPose)]


## ECCV-2022


- Autoregressive 3D Shape Generation via Canonical Mapping [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/2586_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2204.01955)] [[paper with code](https://paperswithcode.com/paper/autoregressive-3d-shape-generation-via)] [[code](https://github.com/AnjieCheng/CanonicalVAE)]

- Cross-Modal 3D Shape Generation and Manipulation [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4596_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.11795)] [[paper with code](https://paperswithcode.com/paper/cross-modal-3d-shape-generation-and)]

- PoseGPT: Quantization-Based 3D Human Motion Generation and Forecasting [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6693_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2210.10542)] [[paper with code](https://paperswithcode.com/paper/posegpt-quantization-based-3d-human-motion)] [[code](https://github.com/naver/posegpt)]

- TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/650_ECCV_2022_paper.php)] [[arxiv](https://arxiv.org/abs/2207.01696)] [[paper with code](https://paperswithcode.com/paper/tm2t-stochastic-and-tokenized-modeling-for)] [[code](https://github.com/EricGuo5513/TM2T)]


## ICML-2022


- Equivariant Diffusion for Molecule Generation in 3D [[paper](https://proceedings.mlr.press/v162/hoogeboom22a.html)] [[arxiv](https://arxiv.org/abs/2309.17296)] [[paper with code](https://paperswithcode.com/paper/equivariant-diffusion-for-molecule-generation)] [[code](https://github.com/ehoogeboom/e3_diffusion_for_molecules)]


## AAAI-2022


- DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20014)] [[arxiv](https://arxiv.org/abs/2103.10206)] [[paper with code](https://paperswithcode.com/paper/dancenet3d-music-based-dance-generation-with)] [[code](https://github.com/libuyu/phantomdancedataset)]

- EditVAE: Unsupervised Parts-Aware Controllable 3D Point Cloud Shape Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20027)] [[arxiv](https://arxiv.org/abs/2110.06679)]



# 2021


## NeurIPS-2021


- GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/725215ed82ab6306919b485b81ff9615-Abstract.html)] [[arxiv](https://arxiv.org/abs/2106.07802)] [[paper with code](https://paperswithcode.com/paper/geomol-torsional-geometric-generation-of)] [[code](https://github.com/PattanaikL/GeoMol)]


## CVPR-2021


- Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Generative_PointNet_Deep_Energy-Based_Learning_on_Unordered_Point_Sets_for_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2004.01301)] [[paper with code](https://paperswithcode.com/paper/generative-pointnet-energy-based-learning-on)] [[code](https://github.com/fei960922/GPointNet)]

- 3D Shape Generation With Grid-Based Implicit Functions [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Ibing_3D_Shape_Generation_With_Grid-Based_Implicit_Functions_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2107.10607)] [[paper with code](https://paperswithcode.com/paper/3d-shape-generation-with-grid-based-implicit-1)]

- Lifting 2D StyleGAN for 3D-Aware Face Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Lifting_2D_StyleGAN_for_3D-Aware_Face_Generation_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2011.13126)] [[paper with code](https://paperswithcode.com/paper/lifting-2d-stylegan-for-3d-aware-face)] [[code](https://github.com/seasonSH/LiftedGAN)]

- Diffusion Probabilistic Models for 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Diffusion_Probabilistic_Models_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2103.01458)] [[paper with code](https://paperswithcode.com/paper/diffusion-probabilistic-models-for-3d-point)] [[code](https://github.com/luost26/diffusion-point-cloud)]

- Learning Progressive Point Embeddings for 3D Point Cloud Generation [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Learning_Progressive_Point_Embeddings_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html)] [[paper with code](https://paperswithcode.com/paper/learning-progressive-point-embeddings-for-3d)]


## ICCV-2021


- AI Choreographer: Music Conditioned 3D Dance Generation With AIST++ [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Li_AI_Choreographer_Music_Conditioned_3D_Dance_Generation_With_AIST_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2101.08779)] [[paper with code](https://paperswithcode.com/paper/learn-to-dance-with-aist-music-conditioned-3d)] [[code](https://github.com/google-research/mint)]

- 3D Shape Generation and Completion Through Point-Voxel Diffusion [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Zhou_3D_Shape_Generation_and_Completion_Through_Point-Voxel_Diffusion_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2104.03670)] [[paper with code](https://paperswithcode.com/paper/3d-shape-generation-and-completion-through)] [[code](https://github.com/alexzhou907/pvd)]

- Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projections Matching [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.03746)] [[paper with code](https://paperswithcode.com/paper/unsupervised-learning-of-fine-structure-1)] [[code](https://github.com/chenchao15/2d_projection_matching)]

- Deep Hybrid Self-Prior for Full 3D Mesh Generation [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Wei_Deep_Hybrid_Self-Prior_for_Full_3D_Mesh_Generation_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.08017)] [[paper with code](https://paperswithcode.com/paper/deep-hybrid-self-prior-for-full-3d-mesh)]

- Graph-to-3D: End-to-End Generation and Manipulation of 3D Scenes Using Scene Graphs [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Dhamo_Graph-to-3D_End-to-End_Generation_and_Manipulation_of_3D_Scenes_Using_Scene_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.08841)] [[paper with code](https://paperswithcode.com/paper/graph-to-3d-end-to-end-generation-and)] [[code](https://github.com/he-dhamo/graphto3d)]

- SPG: Unsupervised Domain Adaptation for 3D Object Detection via Semantic Point Generation [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Xu_SPG_Unsupervised_Domain_Adaptation_for_3D_Object_Detection_via_Semantic_ICCV_2021_paper.html)] [[arxiv](https://arxiv.org/abs/2108.06709)] [[paper with code](https://paperswithcode.com/paper/spg-unsupervised-domain-adaptation-for-3d)]


## AAAI-2021


- Single View Point Cloud Generation via Unified 3D Prototype [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16303)]



# 2020


## NeurIPS-2020


- Convolutional Generation of Textured 3D Meshes [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/098d86c982354a96556bd861823ebfbd-Abstract.html)] [[arxiv](https://arxiv.org/abs/2006.07660)] [[paper with code](https://paperswithcode.com/paper/convolutional-generation-of-textured-3d)] [[code](https://github.com/dariopavllo/convmesh)]

- Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic  Flows [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/1349b36b01e0e804a6c2909a6d0ec72a-Abstract.html)] [[arxiv](https://arxiv.org/abs/2007.10973)]

- Unsupervised object-centric video generation and decomposition in 3D [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/hash/20125fd9b2d43e340a35fb0278da235d-Abstract.html)] [[arxiv](https://arxiv.org/abs/2007.06705)] [[paper with code](https://paperswithcode.com/paper/unsupervised-object-centric-video-generation)] [[code](https://github.com/pmh47/o3v)]


## CVPR-2020


- Disentangled and Controllable Face Image Generation via 3D Imitative-Contrastive Learning [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Deng_Disentangled_and_Controllable_Face_Image_Generation_via_3D_Imitative-Contrastive_Learning_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.11660)] [[paper with code](https://paperswithcode.com/paper/disentangled-and-controllable-face-image)] [[code](https://github.com/microsoft/DisentangledFaceGAN)]

- Leveraging 2D Data to Learn Textured 3D Mesh Generation [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Henderson_Leveraging_2D_Data_to_Learn_Textured_3D_Mesh_Generation_CVPR_2020_paper.html)] [[arxiv](https://arxiv.org/abs/2004.04180)] [[paper with code](https://paperswithcode.com/paper/leveraging-2d-data-to-learn-textured-3d-mesh)] [[code](https://github.com/pmh47/textured-mesh-gen)]


## AAAI-2020


- Rank3DGAN: Semantic Mesh Generation Using Relative Attributes [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6011)] [[arxiv](https://arxiv.org/abs/1905.10257)] [[paper with code](https://paperswithcode.com/paper/rank3dgan-semantic-mesh-generation-using)]



# 2019


## NeurIPS-2019


- Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/a4d8e2a7e0d0c102339f97716d2fdfb6-Abstract.html)] [[arxiv](https://arxiv.org/abs/1906.00957)] [[paper with code](https://paperswithcode.com/paper/symmetry-adapted-generation-of-3d-point-sets)] [[code](https://github.com/atomistic-machine-learning/G-SchNet)]

- Learning elementary structures for 3D shape generation and matching [[paper](https://proceedings.neurips.cc/paper_files/paper/2019/hash/d360a502598a4b64b936683b44a5523a-Abstract.html)] [[arxiv](https://arxiv.org/abs/1908.04725)] [[paper with code](https://paperswithcode.com/paper/learning-elementary-structures-for-3d-shape)] [[code](https://github.com/TheoDEPRELLE/AtlasNetV2)]


## CVPR-2019


- PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_PointRCNN_3D_Object_Proposal_Generation_and_Detection_From_Point_Cloud_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1812.04244)] [[paper with code](https://paperswithcode.com/paper/pointrcnn-3d-object-proposal-generation-and)] [[code](https://github.com/sshaoshuai/PointRCNN)]


## ICCV-2019


- Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Wen_Pixel2Mesh_Multi-View_3D_Mesh_Generation_via_Deformation_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1908.01491)] [[paper with code](https://paperswithcode.com/paper/pixel2mesh-multi-view-3d-mesh-generation-via)] [[code](https://github.com/walsvid/Pixel2MeshPlusPlus)]

- Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Sharma_Monocular_3D_Human_Pose_Estimation_by_Generation_and_Ordinal_Ranking_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.01324)] [[paper with code](https://paperswithcode.com/paper/monocular-3d-human-pose-estimation-by-1)] [[code](https://github.com/ssfootball04/generative_pose)]

- PointFlow: 3D Point Cloud Generation With Continuous Normalizing Flows [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Yang_PointFlow_3D_Point_Cloud_Generation_With_Continuous_Normalizing_Flows_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1906.12320)] [[paper with code](https://paperswithcode.com/paper/pointflow-3d-point-cloud-generation-with)] [[code](https://github.com/stevenygd/PointFlow)]

- Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape Representation Learning and Generation [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Bouritsas_Neural_3D_Morphable_Models_Spiral_Convolutional_Networks_for_3D_Shape_ICCV_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1905.02876)] [[paper with code](https://paperswithcode.com/paper/neural-3d-morphable-models-spiral)] [[code](https://github.com/gbouritsas/Neural3DMM)]


# 2018


## NeurIPS-2018


- Visual Object Networks: Image Generation with Disentangled 3D Representations [[paper](https://proceedings.neurips.cc/paper_files/paper/2018/hash/92cc227532d17e56e07902b254dfad10-Abstract.html)] [[arxiv](https://arxiv.org/abs/1812.02725)] [[paper with code](https://paperswithcode.com/paper/visual-object-networks-image-generation-with-1)] [[code](https://github.com/junyanz/VON)]


## CVPR-2018


- A Papier-Mâché Approach to Learning 3D Surface Generation [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html)] [[arxiv](https://arxiv.org/abs/1802.05384)]


## AAAI-2018


- Learning Adversarial 3D Model Generation With 2D Image Enhancer [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/12223)]

- Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/12278)] [[arxiv](https://arxiv.org/abs/1706.07036)] [[paper with code](https://paperswithcode.com/paper/learning-efficient-point-cloud-generation-for)] [[code](https://github.com/chenhsuanlin/3D-point-cloud-generation)]